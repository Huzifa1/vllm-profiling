{
    "env": {
        "VLLM_USE_V1": 1,
        "CUDA_VISIBLE_DEVICES": "0",
        "VLLM_LOGGING_LEVEL": "DEBUG"
    },
    "params": {
        "model": [
            "/models/llama2-13b-hf",
            "/models/qwen-4b"
        ],
        "cuda-graph-sizes": [1, 8, 16, 32, 64, 128, 256, 512]
    }
}