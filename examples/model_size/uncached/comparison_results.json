{
    "labels": [
        "output_model_falcon-7b.txt",
        "output_model_llama2-13b-hf.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_llama3-3b.txt",
        "output_model_qwen-0.5b.txt",
        "output_model_qwen-1.8b.txt",
        "output_model_qwen-14b.txt",
        "output_model_qwen-4b.txt",
        "output_model_qwen-7b.txt",
        "output_model_yi-6b.txt",
        "output_model_yi-9b.txt"
    ],
    "data": {
        "load_weights": [
            11.46,
            56.04,
            29.33,
            0.9,
            2.03,
            4.8,
            7.97,
            16.42,
            9.4,
            1.64,
            2.4
        ],
        "model_init": [
            0.11,
            0.12,
            0.11,
            0.14,
            0.09,
            0.12,
            0.1,
            0.12,
            0.11,
            0.11,
            0.13
        ],
        "model_loading": [
            11.569817,
            56.16411,
            29.444619,
            1.038698,
            2.129251,
            4.921785,
            8.072701,
            16.546597,
            9.515016,
            1.753025,
            2.53136
        ],
        "dynamo_transform_time": [
            3.96,
            5.97,
            5.01,
            4.22,
            3.72,
            6.21,
            3.75,
            6.06,
            4.95,
            4.99,
            7.16
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_cached": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "torch.compile": [
            20.03,
            29.59,
            23.29,
            21.91,
            19.04,
            29.12,
            19.15,
            29.59,
            26.08,
            23.84,
            34.72
        ],
        "kv_cache_profiling": [
            31.4,
            42.05,
            32.98,
            31.52,
            25.29,
            41.53,
            25.85,
            40.34,
            35.78,
            35.25,
            50.95
        ],
        "graph_capturing": [
            1.53,
            2.42,
            1.54,
            1.04,
            0.7,
            2.41,
            0.76,
            1.26,
            1.56,
            1.46,
            2.04
        ],
        "init_engine": [
            33.4,
            44.99,
            35.0,
            33.03,
            26.43,
            44.46,
            27.06,
            42.1,
            37.82,
            37.2,
            53.52
        ],
        "tokenizer_init": [
            0.12,
            0.09,
            0.08,
            0.28,
            0.26,
            0.24,
            0.26,
            0.27,
            0.27,
            0.15,
            0.15
        ],
        "total_time": [
            45.089817,
            101.24411,
            64.524619,
            34.348698,
            28.819251,
            49.621785,
            35.392700999999995,
            58.916597,
            47.605016,
            39.103025,
            56.20136
        ],
        "actual_total_time": [
            55.55,
            111.41,
            74.65,
            44.69,
            39.15,
            59.9,
            45.73,
            69.24,
            57.95,
            49.31,
            66.38
        ]
    }
}