{
    "labels": [
        "output_model_falcon-7b.txt",
        "output_model_llama2-13b-hf.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_llama3-3b.txt",
        "output_model_qwen-0.5b.txt",
        "output_model_qwen-1.8b.txt",
        "output_model_qwen-14b.txt",
        "output_model_qwen-4b.txt",
        "output_model_qwen-7b.txt",
        "output_model_yi-6b.txt",
        "output_model_yi-9b.txt"
    ],
    "data": {
        "load_weights": [
            8.12,
            14.61,
            7.4,
            3.64,
            0.59,
            2.32,
            15.35,
            5.02,
            9.38,
            6.77,
            9.88
        ],
        "model_init": [
            0.22,
            0.25,
            0.22,
            0.27,
            0.21,
            0.21,
            0.23,
            0.21,
            0.23,
            0.22,
            0.26
        ],
        "model_loading": [
            8.342414,
            14.868696,
            7.634813,
            3.917882,
            0.800051,
            2.534167,
            15.588943,
            5.23939,
            9.617468,
            6.999861,
            10.141689
        ],
        "dynamo_transform_time": [
            7.73,
            10.96,
            8.85,
            8.31,
            7.32,
            7.22,
            10.76,
            10.16,
            9.01,
            9.03,
            12.76
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_cached": [
            6.103,
            10.042,
            8.046,
            6.111,
            5.122,
            5.378,
            9.842,
            9.039,
            6.853,
            7.233,
            10.966
        ],
        "torch.compile": [
            7.73,
            10.96,
            8.85,
            8.31,
            7.32,
            7.22,
            10.76,
            10.16,
            9.01,
            9.03,
            12.76
        ],
        "kv_cache_profiling": [
            17.1,
            26.05,
            19.19,
            17.32,
            14.27,
            14.45,
            25.68,
            22.68,
            18.18,
            18.52,
            27.03
        ],
        "graph_capturing": [
            20.61,
            23.24,
            21.23,
            18.61,
            17.22,
            16.88,
            23.01,
            21.16,
            20.19,
            20.68,
            23.4
        ],
        "kv_cache_init": [
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01,
            0.01
        ],
        "init_engine": [
            38.17,
            49.75,
            40.86,
            36.35,
            31.97,
            31.73,
            49.15,
            44.28,
            38.8,
            39.62,
            50.9
        ],
        "tokenizer_init": [
            0.17,
            0.14,
            0.12,
            0.45,
            0.38,
            0.39,
            0.42,
            0.37,
            0.39,
            0.24,
            0.24
        ],
        "total_time": [
            46.682414,
            64.758696,
            48.614813,
            40.717882,
            33.150051000000005,
            34.654167,
            65.15894300000001,
            49.88939,
            48.807468,
            46.859861,
            61.281689
        ],
        "actual_total_time": [
            61.2,
            79.6,
            63.02,
            55.61,
            48.48,
            49.41,
            85.0,
            64.18,
            64.21,
            61.89,
            76.27
        ]
    }
}