{
    "labels": [
        "output_model_falcon-7b.txt",
        "output_model_llama2-13b-hf.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_llama3-3b.txt",
        "output_model_qwen-0.5b.txt",
        "output_model_qwen-14b.txt",
        "output_model_qwen-1.8b.txt",
        "output_model_qwen-4b.txt",
        "output_model_qwen-7b.txt",
        "output_model_yi-6b.txt",
        "output_model_yi-9b.txt"
    ],
    "data": {
        "detect_platform": [
            0.015,
            0.016,
            0.016,
            0.016,
            0.015,
            0.016,
            0.015,
            0.016,
            0.016,
            0.017,
            0.016
        ],
        "llm_imports": [
            1.388,
            1.391,
            1.39,
            1.401,
            1.382,
            1.389,
            1.391,
            1.393,
            1.406,
            1.585,
            1.387
        ],
        "get_model_info": [
            4.894,
            4.873,
            4.878,
            4.863,
            4.827,
            4.831,
            4.815,
            4.878,
            4.861,
            4.954,
            4.849
        ],
        "worker_init": [
            1.719,
            1.693,
            1.726,
            1.723,
            1.723,
            1.703,
            1.696,
            1.702,
            1.747,
            1.741,
            1.69
        ],
        "framework_bootstrap": [
            8.016,
            7.973000000000001,
            8.01,
            8.003,
            7.947,
            7.939000000000001,
            7.917,
            7.989,
            8.03,
            8.296999999999999,
            7.942
        ],
        "load_weights": [
            24.47,
            47.75,
            24.72,
            11.79,
            1.71,
            51.99,
            6.74,
            14.52,
            28.35,
            22.57,
            32.38
        ],
        "model_init": [
            0.12,
            0.15,
            0.12,
            0.14,
            0.1,
            0.13,
            0.11,
            0.13,
            0.12,
            0.13,
            0.14
        ],
        "model_loading": [
            24.591498,
            47.909208,
            24.846615,
            11.933228,
            1.812903,
            52.122944,
            6.853651,
            14.651146,
            28.479114,
            22.698608,
            32.528587
        ],
        "dynamo_transform_time": [
            5.54,
            6.83,
            5.63,
            4.8,
            4.27,
            6.97,
            4.26,
            6.97,
            5.77,
            5.65,
            8.0
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            23.64
        ],
        "graph_compile_cached": [
            4.396,
            5.852,
            4.569,
            4.245,
            3.368,
            5.873,
            3.403,
            5.762,
            4.582,
            4.869,
            null
        ],
        "torch.compile": [
            5.54,
            6.83,
            5.63,
            4.8,
            4.27,
            6.97,
            4.26,
            6.97,
            5.77,
            5.65,
            31.64
        ],
        "kv_cache_profiling": [
            2.394,
            2.587999999999999,
            1.5909999999999993,
            1.6750000000000007,
            1.5820000000000007,
            2.6270000000000007,
            1.5869999999999997,
            1.8580000000000005,
            1.677999999999999,
            1.5909999999999993,
            4.990000000000002
        ],
        "graph_capturing": [
            1.17,
            1.49,
            1.13,
            1.04,
            0.95,
            1.55,
            0.93,
            1.34,
            1.17,
            1.15,
            1.61
        ],
        "init_engine": [
            13.96,
            17.24,
            13.38,
            12.22,
            10.6,
            17.49,
            10.62,
            16.41,
            13.65,
            13.72,
            38.79
        ],
        "tokenizer_init": [
            0.12,
            0.09,
            0.09,
            0.31,
            0.26,
            0.27,
            0.26,
            0.27,
            0.26,
            0.17,
            0.17
        ],
        "total_time": [
            46.687498,
            73.212208,
            46.326615000000004,
            32.466228,
            20.619903,
            77.82194399999999,
            25.650651,
            39.320146,
            50.41911399999999,
            44.885608,
            79.430587
        ],
        "actual_total_time": [
            48.339,
            74.046,
            47.165,
            33.516,
            21.652,
            78.811,
            26.655,
            40.321,
            51.425,
            45.797,
            80.357
        ]
    }
}