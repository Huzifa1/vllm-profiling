DEBUG 02-16 16:46:51.696 [__init__.py:30] No plugins for group vllm.platform_plugins found.
DEBUG 02-16 16:46:51.696 [__init__.py:35] Checking if TPU platform is available.
DEBUG 02-16 16:46:51.696 [__init__.py:45] TPU platform is not available because: No module named 'libtpu'
DEBUG 02-16 16:46:51.696 [__init__.py:52] Checking if CUDA platform is available.
DEBUG 02-16 16:46:51.709 [__init__.py:72] Confirmed CUDA platform is available.
DEBUG 02-16 16:46:51.718 [__init__.py:100] Checking if ROCm platform is available.
DEBUG 02-16 16:46:51.718 [__init__.py:114] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 02-16 16:46:51.718 [__init__.py:121] Checking if XPU platform is available.
DEBUG 02-16 16:46:51.718 [__init__.py:140] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 02-16 16:46:51.718 [__init__.py:147] Checking if CPU platform is available.
DEBUG 02-16 16:46:51.718 [__init__.py:169] Checking if Neuron platform is available.
DEBUG 02-16 16:46:51.718 [__init__.py:52] Checking if CUDA platform is available.
DEBUG 02-16 16:46:51.722 [__init__.py:72] Confirmed CUDA platform is available.
INFO 02-16 16:46:51.730 [__init__.py:235] Automatically detected platform cuda.
DEBUG 02-16 16:46:53.330 [__init__.py:38] Available plugins for group vllm.general_plugins:
DEBUG 02-16 16:46:53.330 [__init__.py:40] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
DEBUG 02-16 16:46:53.330 [__init__.py:43] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
DEBUG 02-16 16:46:57.967 [config.py:579] Tasks supported by runner type: {'generate': ['generate'], 'pooling': ['encode', 'embed'], 'draft': ['draft']}
DEBUG 02-16 16:46:57.967 [config.py:586] Selected runner type: generate
INFO 02-16 16:46:57.983 [config.py:1604] Using max model len 2048
INFO 02-16 16:46:58.137 [config.py:2434] Chunked prefill is enabled with max_num_batched_tokens=2048.
DEBUG 02-16 16:46:58.138 [llm_engine.py:148] Enabling multiprocessing for LLMEngine.
INFO 02-16 16:46:58.249 [core.py:572] Waiting for init message from front-end.
DEBUG 02-16 16:46:58.249 [utils.py:822] HELLO from local core engine process 0.
DEBUG 02-16 16:46:58.249 [core.py:580] Received init message: EngineHandshakeMetadata(addresses=EngineZmqAddresses(inputs=['ipc:///tmp/6a33130d-f62e-4827-9f46-6c7644134efe'], outputs=['ipc:///tmp/9cf087c9-a233-4a52-832a-1bb80a9629ce'], coordinator_input=None, coordinator_output=None, frontend_stats_publish_address=None), parallel_config={'data_parallel_master_ip': '127.0.0.1', 'data_parallel_master_port': 0, 'data_parallel_size': 1})
INFO 02-16 16:46:58.251 [core.py:71] Initializing a V1 LLM engine (v0.10.0) with config: model='../../models/opt-6.7b', speculative_config=None, tokenizer='../../models/opt-6.7b', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=../../models/opt-6.7b, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"max_capture_size":256,"local_cache_dir":null}
DEBUG 02-16 16:46:59.360 [decorators.py:139] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama.LlamaModel'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
DEBUG 02-16 16:46:59.361 [decorators.py:139] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama_eagle3.LlamaModel'>: ['input_ids', 'positions', 'hidden_states']
DEBUG 02-16 16:46:59.478 [__init__.py:3051] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fbbddde3210>
DEBUG 02-16 16:46:59.478 [config.py:4871] enabled custom ops: Counter()
DEBUG 02-16 16:46:59.478 [config.py:4873] disabled custom ops: Counter()
DEBUG 02-16 16:46:59.838 [parallel_state.py:945] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://131.234.187.204:36099 backend=nccl
DEBUG 02-16 16:46:59.844 [parallel_state.py:996] Detected 1 nodes in the distributed environment
INFO 02-16 16:46:59.847 [parallel_state.py:1102] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
WARNING 02-16 16:46:59.849 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
DEBUG 02-16 16:46:59.853 [decorators.py:139] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.opt.OPTModel'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
DEBUG 02-16 16:46:59.854 [config.py:4871] enabled custom ops: Counter()
DEBUG 02-16 16:46:59.854 [config.py:4873] disabled custom ops: Counter()
INFO 02-16 16:46:59.854 [gpu_model_runner.py:1843] Starting to load model ../../models/opt-6.7b...
INFO 02-16 16:47:00.048 [gpu_model_runner.py:1875] Loading model from scratch...
INFO 02-16 16:47:00.052 [cuda.py:290] Using Flash Attention backend on V1 engine.
DEBUG 02-16 16:47:00.103 [backends.py:39] Using InductorAdaptor
DEBUG 02-16 16:47:00.121 [config.py:4871] enabled custom ops: Counter()
DEBUG 02-16 16:47:00.121 [config.py:4873] disabled custom ops: Counter()
DEBUG 02-16 16:47:00.121 [base_loader.py:47] Loading weights on cuda ...
INFO 02-16 16:47:03.002 [default_loader.py:262] Loading weights took 2.88 seconds
INFO 02-16 16:47:03.389 [gpu_model_runner.py:1892] Model loading took 12.4037 GiB and 2.956168 seconds
DEBUG 02-16 16:47:03.577 [decorators.py:237] Start compiling function <code object forward at 0x7fbcbe4b8030, file "/local/huzaifa/vllm-profiling/figures/figure-1/.venv-0.10.0/lib/python3.11/site-packages/vllm/model_executor/models/opt.py", line 305>
DEBUG 02-16 16:47:06.052 [backends.py:483] Traced files (to be considered for compilation cache):
DEBUG 02-16 16:47:06.052 [backends.py:483] /local/huzaifa/vllm-profiling/figures/figure-1/.venv-0.10.0/lib/python3.11/site-packages/torch/_dynamo/polyfills/__init__.py
DEBUG 02-16 16:47:06.052 [backends.py:483] /local/huzaifa/vllm-profiling/figures/figure-1/.venv-0.10.0/lib/python3.11/site-packages/torch/nn/modules/activation.py
DEBUG 02-16 16:47:06.052 [backends.py:483] /local/huzaifa/vllm-profiling/figures/figure-1/.venv-0.10.0/lib/python3.11/site-packages/torch/nn/modules/container.py
DEBUG 02-16 16:47:06.052 [backends.py:483] /local/huzaifa/vllm-profiling/figures/figure-1/.venv-0.10.0/lib/python3.11/site-packages/torch/nn/modules/module.py
DEBUG 02-16 16:47:06.052 [backends.py:483] /local/huzaifa/vllm-profiling/figures/figure-1/.venv-0.10.0/lib/python3.11/site-packages/torch/nn/modules/normalization.py
DEBUG 02-16 16:47:06.052 [backends.py:483] /local/huzaifa/vllm-profiling/figures/figure-1/.venv-0.10.0/lib/python3.11/site-packages/torch/nn/modules/sparse.py
DEBUG 02-16 16:47:06.052 [backends.py:483] /local/huzaifa/vllm-profiling/figures/figure-1/.venv-0.10.0/lib/python3.11/site-packages/vllm/attention/layer.py
DEBUG 02-16 16:47:06.052 [backends.py:483] /local/huzaifa/vllm-profiling/figures/figure-1/.venv-0.10.0/lib/python3.11/site-packages/vllm/distributed/communication_op.py
DEBUG 02-16 16:47:06.052 [backends.py:483] /local/huzaifa/vllm-profiling/figures/figure-1/.venv-0.10.0/lib/python3.11/site-packages/vllm/distributed/parallel_state.py
DEBUG 02-16 16:47:06.052 [backends.py:483] /local/huzaifa/vllm-profiling/figures/figure-1/.venv-0.10.0/lib/python3.11/site-packages/vllm/model_executor/layers/linear.py
DEBUG 02-16 16:47:06.052 [backends.py:483] /local/huzaifa/vllm-profiling/figures/figure-1/.venv-0.10.0/lib/python3.11/site-packages/vllm/model_executor/layers/utils.py
DEBUG 02-16 16:47:06.052 [backends.py:483] /local/huzaifa/vllm-profiling/figures/figure-1/.venv-0.10.0/lib/python3.11/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py
DEBUG 02-16 16:47:06.052 [backends.py:483] /local/huzaifa/vllm-profiling/figures/figure-1/.venv-0.10.0/lib/python3.11/site-packages/vllm/model_executor/models/opt.py
DEBUG 02-16 16:47:06.052 [backends.py:483] /local/huzaifa/vllm-profiling/figures/figure-1/.venv-0.10.0/lib/python3.11/site-packages/vllm/platforms/interface.py
INFO 02-16 16:47:06.344 [backends.py:530] Using cache directory: /local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/backbone for vLLM's torch.compile
INFO 02-16 16:47:06.346 [backends.py:541] Dynamo bytecode transform time: 2.77 s
DEBUG 02-16 16:47:06.568 [backends.py:124] Directly load the 0-th graph for dynamic shape from inductor via handle ('fwwkfs37gc67gp7u76nnzuc6wuv54xnnc7zjue56y434wxtgpxhz', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/ls/clsn3zvtaxa3xqlf3fycobmsrk4rtpoq6vyy6xysvp6hts3bnwlb.py')
DEBUG 02-16 16:47:06.642 [backends.py:124] Directly load the 1-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:06.716 [backends.py:124] Directly load the 2-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:06.789 [backends.py:124] Directly load the 3-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:06.862 [backends.py:124] Directly load the 4-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:06.935 [backends.py:124] Directly load the 5-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:07.008 [backends.py:124] Directly load the 6-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:07.081 [backends.py:124] Directly load the 7-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:07.155 [backends.py:124] Directly load the 8-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:07.228 [backends.py:124] Directly load the 9-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:07.301 [backends.py:124] Directly load the 10-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:07.375 [backends.py:124] Directly load the 11-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:07.448 [backends.py:124] Directly load the 12-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:07.521 [backends.py:124] Directly load the 13-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:07.594 [backends.py:124] Directly load the 14-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:07.667 [backends.py:124] Directly load the 15-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:07.740 [backends.py:124] Directly load the 16-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:07.813 [backends.py:124] Directly load the 17-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:07.886 [backends.py:124] Directly load the 18-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:07.962 [backends.py:124] Directly load the 19-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:08.253 [utils.py:741] Waiting for 1 local, 0 remote core engine proc(s) to start.
DEBUG 02-16 16:47:08.281 [backends.py:124] Directly load the 20-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:08.355 [backends.py:124] Directly load the 21-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:08.428 [backends.py:124] Directly load the 22-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:08.501 [backends.py:124] Directly load the 23-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:08.575 [backends.py:124] Directly load the 24-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:08.648 [backends.py:124] Directly load the 25-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:08.721 [backends.py:124] Directly load the 26-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:08.794 [backends.py:124] Directly load the 27-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:08.867 [backends.py:124] Directly load the 28-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:08.940 [backends.py:124] Directly load the 29-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:09.012 [backends.py:124] Directly load the 30-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:09.086 [backends.py:124] Directly load the 31-th graph for dynamic shape from inductor via handle ('fzcrgonvmvyesdvgtdodkdzt5exhr6giool42mjqxtqgc6qgcdvl', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/vx/cvxeouwkkopapi4agasqjmkjv3swiozxmecbp2r6he6n7t3biwz5.py')
DEBUG 02-16 16:47:09.147 [backends.py:124] Directly load the 32-th graph for dynamic shape from inductor via handle ('fp5bwdvvgtqnqrrjmwtequrenvekqacmacvwujogqdn5mqpquk4g', '/local/huzaifa/.cache/vllm/torch_compile_cache/50e183f856/rank_0_0/inductor_cache/u5/cu5z77xfgtbqktmnfuaadsot6nwcojgwl4p7v3myfufwzdzd5uyj.py')
INFO 02-16 16:47:09.147 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 2.613 s
INFO 02-16 16:47:10.441 [monitor.py:34] torch.compile takes 2.77 s in total
DEBUG 02-16 16:47:11.051 [gpu_worker.py:249] Initial free memory: 92.48 GiB, free memory: 79.96 GiB, requested GPU memory: 83.78 GiB
DEBUG 02-16 16:47:11.052 [gpu_worker.py:254] Memory profiling takes 7.48 seconds. Total non KV cache memory: 12.75GiB; torch peak memory increase: 0.28GiB; non-torch forward increase memory: 0.07GiB; weights memory: 12.40GiB.
INFO 02-16 16:47:11.052 [gpu_worker.py:255] Available KV cache memory: 71.03 GiB
INFO 02-16 16:47:11.279 [kv_cache_utils.py:833] GPU KV cache size: 145,456 tokens
INFO 02-16 16:47:11.279 [kv_cache_utils.py:837] Maximum concurrency for 2,048 tokens per request: 71.02x
DEBUG 02-16 16:47:11.287 [config.py:4871] enabled custom ops: Counter()
DEBUG 02-16 16:47:11.287 [config.py:4873] disabled custom ops: Counter()
DEBUG 02-16 16:47:11.522 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 256
DEBUG 02-16 16:47:11.544 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 256
DEBUG 02-16 16:47:11.556 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 248
DEBUG 02-16 16:47:11.568 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 248
DEBUG 02-16 16:47:11.578 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 240
DEBUG 02-16 16:47:11.591 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 240
DEBUG 02-16 16:47:11.601 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 232
DEBUG 02-16 16:47:11.615 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 232
DEBUG 02-16 16:47:11.626 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 224
DEBUG 02-16 16:47:11.639 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 224
DEBUG 02-16 16:47:11.650 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 216
DEBUG 02-16 16:47:11.665 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 216
DEBUG 02-16 16:47:11.675 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 208
DEBUG 02-16 16:47:11.687 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 208
DEBUG 02-16 16:47:11.698 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 200
DEBUG 02-16 16:47:11.711 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 200
DEBUG 02-16 16:47:11.722 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 192
DEBUG 02-16 16:47:11.737 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 192
DEBUG 02-16 16:47:11.748 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 184
DEBUG 02-16 16:47:11.761 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 184
DEBUG 02-16 16:47:11.772 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 176
DEBUG 02-16 16:47:11.786 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 176
DEBUG 02-16 16:47:11.797 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 168
DEBUG 02-16 16:47:11.810 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 168
DEBUG 02-16 16:47:11.821 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 160
DEBUG 02-16 16:47:11.837 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 160
DEBUG 02-16 16:47:11.849 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 152
DEBUG 02-16 16:47:11.863 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 152
DEBUG 02-16 16:47:11.874 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 144
DEBUG 02-16 16:47:11.889 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 144
DEBUG 02-16 16:47:11.900 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 136
DEBUG 02-16 16:47:11.912 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 136
DEBUG 02-16 16:47:11.924 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 128
DEBUG 02-16 16:47:11.939 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 128
DEBUG 02-16 16:47:11.951 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 120
DEBUG 02-16 16:47:11.965 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 120
DEBUG 02-16 16:47:11.977 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 112
DEBUG 02-16 16:47:11.992 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 112
DEBUG 02-16 16:47:12.003 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 104
DEBUG 02-16 16:47:12.016 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 104
DEBUG 02-16 16:47:12.028 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 96
DEBUG 02-16 16:47:12.042 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 96
DEBUG 02-16 16:47:12.055 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 88
DEBUG 02-16 16:47:12.067 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 88
DEBUG 02-16 16:47:12.079 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 80
DEBUG 02-16 16:47:12.094 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 80
DEBUG 02-16 16:47:12.109 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 72
DEBUG 02-16 16:47:12.124 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 72
DEBUG 02-16 16:47:12.137 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 64
DEBUG 02-16 16:47:12.151 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 64
DEBUG 02-16 16:47:12.164 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 56
DEBUG 02-16 16:47:12.178 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 56
DEBUG 02-16 16:47:12.190 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 48
DEBUG 02-16 16:47:12.204 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 48
DEBUG 02-16 16:47:12.216 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 40
DEBUG 02-16 16:47:12.230 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 40
DEBUG 02-16 16:47:12.242 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 32
DEBUG 02-16 16:47:12.255 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 32
DEBUG 02-16 16:47:12.267 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 24
DEBUG 02-16 16:47:12.281 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 24
DEBUG 02-16 16:47:12.293 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 16
DEBUG 02-16 16:47:12.306 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 16
DEBUG 02-16 16:47:12.318 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 8
DEBUG 02-16 16:47:12.330 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 8
DEBUG 02-16 16:47:12.343 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 4
DEBUG 02-16 16:47:12.350 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 4
DEBUG 02-16 16:47:12.362 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 2
DEBUG 02-16 16:47:12.369 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 2
DEBUG 02-16 16:47:12.382 [cuda_piecewise_backend.py:151] Warming up 1/1 for shape 1
DEBUG 02-16 16:47:12.389 [cuda_piecewise_backend.py:162] Capturing a cudagraph for shape 1
INFO 02-16 16:47:12.402 [gpu_model_runner.py:2485] Graph capturing finished in 1 secs, took 0.31 GiB
INFO 02-16 16:47:12.410 [core.py:193] init engine (profile, create kv cache, warmup model) took 9.02 seconds
DEBUG 02-16 16:47:12.508 [utils.py:822] READY from local core engine process 0.
DEBUG 02-16 16:47:12.510 [core.py:660] EngineCore waiting for work.
DEBUG 02-16 16:47:12.511 [core.py:660] EngineCore waiting for work.
DEBUG 02-16 16:47:12.512 [core.py:628] EngineCore exiting.
initialize_engine took 19.19 seconds
