{
    "labels": [
        "output_model_falcon-7b.txt",
        "output_model_llama2-13b-hf.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_llama3-3b.txt",
        "output_model_qwen-0.5b.txt",
        "output_model_qwen-14b_max_model_len_16752.txt",
        "output_model_qwen-1.8b.txt",
        "output_model_qwen-4b.txt",
        "output_model_qwen-7b.txt",
        "output_model_yi-6b.txt",
        "output_model_yi-9b.txt"
    ],
    "data": {
        "detect_platform": [
            0.045,
            0.046,
            0.046,
            0.045,
            0.045,
            0.045,
            0.045,
            0.045,
            0.045,
            0.046,
            0.045
        ],
        "llm_imports": [
            1.389,
            1.382,
            1.39,
            1.383,
            1.404,
            1.39,
            1.392,
            1.367,
            1.387,
            1.395,
            1.379
        ],
        "get_model_info": [
            4.96,
            4.954,
            4.969,
            5.009,
            4.949,
            4.969,
            5.0,
            4.978,
            4.964,
            4.988,
            4.939
        ],
        "worker_init": [
            1.941,
            1.94,
            1.945,
            1.972,
            1.961,
            1.978,
            1.969,
            1.948,
            1.981,
            1.949,
            1.943
        ],
        "framework_bootstrap": [
            8.335,
            8.322,
            8.35,
            8.409,
            8.359,
            8.382,
            8.405999999999999,
            8.338,
            8.377,
            8.378,
            8.306
        ],
        "load_weights": [
            1.73,
            3.15,
            1.62,
            0.78,
            0.13,
            3.41,
            0.45,
            16.27,
            31.58,
            24.13,
            35.7
        ],
        "model_init": [
            0.12,
            0.13,
            0.12,
            0.14,
            0.11,
            0.13,
            0.11,
            0.13,
            0.12,
            0.12,
            0.14
        ],
        "model_loading": [
            1.857273,
            3.283178,
            1.747682,
            0.927759,
            0.240522,
            3.545877,
            0.565218,
            16.401461,
            31.709014,
            24.25964,
            35.845335
        ],
        "dynamo_transform_time": [
            4.81,
            6.84,
            5.45,
            4.79,
            4.28,
            6.95,
            4.29,
            6.98,
            5.6,
            5.47,
            8.05
        ],
        "graph_compile_general_shape": [
            16.07,
            21.25,
            17.35,
            16.38,
            13.67,
            21.6,
            13.95,
            21.71,
            17.72,
            17.95,
            25.54
        ],
        "graph_compile_cached": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "torch.compile": [
            20.88,
            28.09,
            22.8,
            21.17,
            17.95,
            28.54,
            18.24,
            28.68,
            23.32,
            23.42,
            33.6
        ],
        "kv_cache_profiling": [
            11.41,
            12.669999999999998,
            10.150000000000002,
            9.59,
            6.289999999999999,
            12.719999999999999,
            6.73,
            10.979999999999997,
            10.200000000000003,
            11.64,
            16.68
        ],
        "graph_capturing": [
            1.61,
            2.47,
            1.59,
            1.1,
            0.77,
            2.49,
            0.82,
            1.33,
            1.62,
            1.51,
            2.11
        ],
        "init_engine": [
            34.46,
            43.85,
            35.12,
            32.41,
            25.54,
            44.36,
            26.32,
            41.57,
            35.72,
            37.14,
            53.01
        ],
        "tokenizer_init": [
            0.12,
            0.08,
            0.08,
            0.29,
            0.25,
            0.24,
            0.25,
            0.25,
            0.26,
            0.16,
            0.17
        ],
        "total_time": [
            44.772273,
            55.535178,
            45.297681999999995,
            42.036758999999996,
            34.389522,
            56.527877,
            35.541218,
            66.559461,
            76.06601400000001,
            69.93764,
            97.331335
        ],
        "actual_total_time": [
            46.167,
            56.436,
            46.188,
            43.152,
            35.451,
            57.604,
            36.592,
            67.613,
            77.136,
            70.926,
            98.302
        ]
    }
}