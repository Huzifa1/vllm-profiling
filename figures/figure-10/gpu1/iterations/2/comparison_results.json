{
    "labels": [
        "output_model_falcon-7b.txt",
        "output_model_llama2-13b-hf.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_llama3-3b.txt",
        "output_model_qwen-0.5b.txt",
        "output_model_qwen-14b_max_model_len_16752.txt",
        "output_model_qwen-1.8b.txt",
        "output_model_qwen-4b.txt",
        "output_model_qwen-7b.txt",
        "output_model_yi-6b.txt",
        "output_model_yi-9b.txt"
    ],
    "data": {
        "detect_platform": [
            0.045,
            0.046,
            0.046,
            0.046,
            0.045,
            0.046,
            0.046,
            0.046,
            0.046,
            0.046,
            0.045
        ],
        "llm_imports": [
            1.395,
            1.381,
            1.392,
            1.377,
            1.383,
            1.386,
            1.373,
            1.383,
            1.4,
            1.397,
            1.387
        ],
        "get_model_info": [
            4.997,
            4.962,
            5.033,
            5.027,
            4.994,
            4.966,
            5.025,
            4.995,
            4.966,
            4.969,
            5.004
        ],
        "worker_init": [
            1.947,
            1.939,
            1.965,
            1.969,
            1.949,
            1.984,
            1.959,
            1.968,
            1.99,
            1.953,
            1.958
        ],
        "framework_bootstrap": [
            8.384,
            8.328,
            8.436,
            8.419,
            8.371,
            8.382,
            8.403,
            8.392,
            8.402,
            8.365,
            8.394
        ],
        "load_weights": [
            1.74,
            3.16,
            1.64,
            0.78,
            0.13,
            3.41,
            0.45,
            0.97,
            1.88,
            1.47,
            2.14
        ],
        "model_init": [
            0.12,
            0.13,
            0.12,
            0.14,
            0.1,
            0.13,
            0.11,
            0.13,
            0.12,
            0.12,
            0.14
        ],
        "model_loading": [
            1.863394,
            3.297801,
            1.760851,
            0.922815,
            0.238521,
            3.54953,
            0.567108,
            1.104403,
            2.007026,
            1.597391,
            2.284604
        ],
        "dynamo_transform_time": [
            4.74,
            6.83,
            5.41,
            4.81,
            4.33,
            7.01,
            4.27,
            6.96,
            5.61,
            5.46,
            7.99
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_cached": [
            4.387,
            5.538,
            4.427,
            4.408,
            3.586,
            5.611,
            3.617,
            5.592,
            4.567,
            4.821,
            7.063
        ],
        "torch.compile": [
            4.74,
            6.83,
            5.41,
            4.81,
            4.33,
            7.01,
            4.27,
            6.96,
            5.61,
            5.46,
            7.99
        ],
        "kv_cache_profiling": [
            1.633000000000001,
            2.081999999999999,
            2.0229999999999997,
            1.5220000000000002,
            1.3940000000000001,
            2.099000000000002,
            1.4130000000000011,
            1.9080000000000013,
            2.0229999999999997,
            1.9990000000000006,
            2.247
        ],
        "graph_capturing": [
            1.53,
            2.38,
            1.52,
            1.03,
            0.69,
            2.4,
            0.77,
            1.25,
            1.55,
            1.42,
            2.03
        ],
        "init_engine": [
            12.8,
            17.38,
            13.9,
            12.27,
            10.48,
            17.68,
            10.57,
            16.23,
            14.26,
            14.22,
            19.89
        ],
        "tokenizer_init": [
            0.12,
            0.08,
            0.08,
            0.28,
            0.25,
            0.25,
            0.25,
            0.25,
            0.25,
            0.15,
            0.16
        ],
        "total_time": [
            23.167394,
            29.085800999999996,
            24.176851,
            21.891815,
            19.339521,
            29.86153,
            19.790108,
            25.976402999999998,
            24.919026,
            24.332391,
            30.728604
        ],
        "actual_total_time": [
            24.485,
            29.992,
            25.068,
            22.993,
            20.403,
            30.923,
            20.855,
            27.031,
            25.973,
            25.313,
            31.702
        ]
    }
}