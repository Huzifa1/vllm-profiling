{
    "labels": [
        "output_model_falcon-7b.txt",
        "output_model_llama2-13b-hf.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_llama3-3b.txt",
        "output_model_qwen-0.5b.txt",
        "output_model_qwen-14b_max_model_len_16752.txt",
        "output_model_qwen-1.8b.txt",
        "output_model_qwen-4b.txt",
        "output_model_qwen-7b.txt",
        "output_model_yi-6b.txt",
        "output_model_yi-9b.txt"
    ],
    "data": {
        "detect_platform": [
            0.034,
            0.034,
            0.034,
            0.034,
            0.034,
            0.034,
            0.034,
            0.034,
            0.034,
            0.034,
            0.034
        ],
        "llm_imports": [
            1.465,
            1.486,
            1.479,
            1.479,
            1.469,
            1.467,
            1.478,
            1.481,
            1.484,
            1.472,
            1.471
        ],
        "get_model_info": [
            5.395,
            5.386,
            5.421,
            5.403,
            5.382,
            5.423,
            5.409,
            5.386,
            5.382,
            5.424,
            5.4
        ],
        "worker_init": [
            1.743,
            1.731,
            1.763,
            1.755,
            1.78,
            1.75,
            1.801,
            1.767,
            1.772,
            1.756,
            1.753
        ],
        "framework_bootstrap": [
            8.637,
            8.637,
            8.697,
            8.671,
            8.665,
            8.674,
            8.722,
            8.668,
            8.671999999999999,
            8.686,
            8.658
        ],
        "load_weights": [
            24.48,
            47.84,
            24.77,
            11.8,
            0.13,
            52.01,
            6.74,
            14.5,
            28.34,
            22.25,
            32.42
        ],
        "model_init": [
            0.12,
            0.13,
            0.12,
            0.14,
            0.1,
            0.13,
            0.11,
            0.13,
            0.12,
            0.12,
            0.14
        ],
        "model_loading": [
            24.601718,
            47.980362,
            24.894537,
            11.939041,
            0.237035,
            52.145073,
            6.851995,
            14.637451,
            28.463639,
            22.371196,
            32.567565
        ],
        "dynamo_transform_time": [
            4.76,
            6.83,
            5.35,
            4.82,
            4.3,
            6.96,
            4.25,
            7.02,
            5.5,
            5.38,
            8.03
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            16.65,
            13.76,
            22.03,
            13.83,
            21.84,
            17.73,
            null,
            25.62
        ],
        "graph_compile_cached": [
            4.277,
            5.699,
            4.468,
            null,
            null,
            null,
            null,
            null,
            null,
            4.738,
            null
        ],
        "torch.compile": [
            4.76,
            6.83,
            5.35,
            21.47,
            18.06,
            28.99,
            18.08,
            28.86,
            23.24,
            5.38,
            33.65
        ],
        "kv_cache_profiling": [
            2.4430000000000014,
            2.6310000000000002,
            1.9420000000000002,
            3.09,
            2.4400000000000013,
            5.0000000000000036,
            2.8800000000000026,
            3.6400000000000006,
            3.7200000000000024,
            1.9320000000000004,
            5.020000000000003
        ],
        "graph_capturing": [
            1.18,
            1.48,
            1.13,
            1.13,
            1.03,
            1.61,
            1.02,
            1.44,
            1.23,
            1.17,
            1.59
        ],
        "init_engine": [
            13.14,
            17.16,
            13.4,
            26.23,
            22.06,
            36.18,
            22.5,
            34.51,
            28.75,
            13.72,
            40.86
        ],
        "tokenizer_init": [
            0.12,
            0.09,
            0.09,
            0.3,
            0.25,
            0.26,
            0.26,
            0.26,
            0.26,
            0.16,
            0.16
        ],
        "total_time": [
            46.498718000000004,
            73.867362,
            47.081537000000004,
            47.140041,
            31.212035,
            97.259073,
            38.333994999999994,
            58.075450999999994,
            66.145639,
            44.937196,
            82.245565
        ],
        "actual_total_time": [
            48.248,
            74.76,
            47.957,
            48.253,
            32.266,
            98.33,
            39.392,
            59.132,
            67.193,
            45.932,
            83.237
        ]
    }
}