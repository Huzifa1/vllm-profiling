{
    "env": {
        "VLLM_USE_V1": 1,
        "CUDA_VISIBLE_DEVICES": "0",
        "VLLM_LOGGING_LEVEL": "DEBUG"
    },
    "default_params": {
        "max-model-len": [256, 512, 1024, 2048, 4096, 8192, 16384, 32768]
    },
    "configs": [
        {"model": "/local/huzaifa/workspace/models/llama2-13b-hf"},
        {"model": "/local/huzaifa/workspace/models/qwen-4b"}
    ],
    "notes": "Llama2-13b supports up to 4096, Qwen-4b supports up to 32768"
}
