{
    "env": {
        "VLLM_USE_V1": 1,
        "CUDA_VISIBLE_DEVICES": "0",
        "VLLM_LOGGING_LEVEL": "DEBUG"
    },
    "params": {
        "model": [
            "/models/llama2-7b-hf",
            "/models/qwen-1.8b"
        ],
        "cuda-graph-sizes": [1, 8, 32, 128, 256, 512, 1024]
    }
}