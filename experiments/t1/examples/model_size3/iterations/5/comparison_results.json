{
    "labels": [
        "output_model_falcon-7b.txt",
        "output_model_llama2-13b-hf.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_llama3-3b.txt",
        "output_model_qwen-0.5b.txt",
        "output_model_qwen-14b.txt",
        "output_model_qwen-1.8b.txt",
        "output_model_qwen-4b.txt",
        "output_model_qwen-7b.txt",
        "output_model_yi-6b.txt",
        "output_model_yi-9b.txt"
    ],
    "data": {
        "detect_platfrom": [
            0.367,
            0.341,
            0.342,
            0.34,
            0.342,
            0.369,
            0.363,
            0.342,
            0.345,
            0.496,
            0.504
        ],
        "llm_imports": [
            1.273,
            1.229,
            1.384,
            1.256,
            1.434,
            1.233,
            1.214,
            1.23,
            1.238,
            1.274,
            1.345
        ],
        "get_model_info": [
            6.93,
            6.529,
            6.679,
            6.505,
            7.068,
            6.988,
            6.852,
            7.281,
            6.54,
            7.963,
            6.57
        ],
        "worker_init": [
            2.147,
            2.062,
            2.117,
            2.484,
            2.325,
            2.393,
            2.139,
            2.188,
            2.299,
            2.141,
            2.159
        ],
        "framework_bootstrap": [
            10.717,
            10.161,
            10.522000000000002,
            10.584999999999999,
            11.169,
            10.983,
            10.568,
            11.041,
            10.421999999999999,
            11.874,
            10.578
        ],
        "load_weights": [
            2.19,
            3.84,
            1.93,
            1.17,
            0.18,
            3.98,
            0.55,
            1.12,
            2.15,
            1.69,
            2.46
        ],
        "model_init": [
            0.1,
            0.11,
            0.11,
            0.12,
            0.09,
            0.11,
            0.1,
            0.21,
            0.1,
            0.11,
            0.12
        ],
        "model_loading": [
            2.893766,
            4.604091,
            2.578347,
            1.943706,
            3.255722,
            4.626586,
            1.290634,
            1.861305,
            2.936214,
            2.349074,
            3.103394
        ],
        "dynamo_transform_time": [
            3.84,
            5.37,
            4.51,
            3.81,
            3.35,
            5.48,
            3.34,
            5.44,
            4.54,
            4.35,
            6.36
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_cached": [
            3.368,
            4.518,
            3.538,
            3.248,
            2.448,
            4.592,
            2.54,
            4.376,
            3.48,
            3.518,
            5.484
        ],
        "torch.compile": [
            3.84,
            5.37,
            4.51,
            3.81,
            3.35,
            5.48,
            3.34,
            5.44,
            4.54,
            4.35,
            6.36
        ],
        "kv_cache_profiling": [
            2.1020000000000003,
            2.2520000000000007,
            1.1920000000000002,
            1.3919999999999995,
            1.1420000000000003,
            2.1880000000000006,
            1.2300000000000004,
            1.4139999999999997,
            1.1799999999999997,
            1.2020000000000008,
            1.8659999999999997
        ],
        "graph_capturing": [
            1.18,
            1.47,
            1.12,
            1.06,
            0.78,
            1.49,
            1.24,
            1.24,
            1.14,
            0.95,
            1.44
        ],
        "init_engine": [
            10.74,
            13.86,
            10.58,
            9.74,
            7.95,
            13.97,
            8.55,
            12.82,
            10.55,
            10.29,
            15.53
        ],
        "tokenizer_init": [
            0.37,
            0.32,
            0.5,
            0.51,
            0.48,
            0.65,
            0.5,
            0.71,
            0.51,
            0.43,
            0.42
        ],
        "total_time": [
            24.720766,
            28.945090999999998,
            24.180347000000005,
            22.778706000000003,
            22.854722000000002,
            30.229585999999998,
            20.908634,
            26.432305,
            24.418214000000003,
            24.943074,
            29.631394
        ],
        "actual_total_time": [
            26.34,
            29.981,
            25.192,
            23.928,
            23.962,
            31.38,
            22.048,
            27.536,
            25.547,
            25.961,
            30.95
        ]
    }
}