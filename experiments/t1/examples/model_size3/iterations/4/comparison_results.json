{
    "labels": [
        "output_model_falcon-7b.txt",
        "output_model_llama2-13b-hf.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_llama3-3b.txt",
        "output_model_qwen-0.5b.txt",
        "output_model_qwen-14b.txt",
        "output_model_qwen-1.8b.txt",
        "output_model_qwen-4b.txt",
        "output_model_qwen-7b.txt",
        "output_model_yi-6b.txt",
        "output_model_yi-9b.txt"
    ],
    "data": {
        "detect_platfrom": [
            0.343,
            0.357,
            0.34,
            0.34,
            0.506,
            0.481,
            0.344,
            0.341,
            0.505,
            0.363,
            0.346
        ],
        "llm_imports": [
            1.327,
            1.267,
            1.444,
            1.447,
            1.289,
            1.261,
            1.428,
            1.416,
            1.279,
            1.276,
            1.219
        ],
        "get_model_info": [
            6.454,
            6.613,
            6.646,
            6.616,
            6.867,
            6.891,
            6.78,
            6.716,
            6.672,
            6.69,
            6.956
        ],
        "worker_init": [
            2.348,
            2.281,
            2.278,
            2.271,
            2.227,
            2.2,
            2.286,
            2.3,
            2.274,
            2.222,
            2.129
        ],
        "framework_bootstrap": [
            10.471999999999998,
            10.518,
            10.708,
            10.674,
            10.889,
            10.832999999999998,
            10.838,
            10.773,
            10.73,
            10.551,
            10.65
        ],
        "load_weights": [
            2.2,
            3.84,
            1.93,
            0.92,
            0.15,
            4.45,
            0.6,
            1.14,
            2.17,
            1.88,
            2.47
        ],
        "model_init": [
            0.1,
            0.11,
            0.1,
            0.12,
            0.09,
            0.11,
            0.1,
            0.11,
            0.11,
            0.1,
            0.12
        ],
        "model_loading": [
            2.786285,
            4.455824,
            2.517422,
            1.552459,
            0.722981,
            5.050316,
            1.153348,
            1.906226,
            2.952939,
            2.558052,
            3.286485
        ],
        "dynamo_transform_time": [
            3.84,
            5.34,
            4.46,
            3.79,
            3.39,
            5.53,
            3.39,
            5.49,
            4.55,
            4.46,
            6.29
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_cached": [
            3.332,
            4.457,
            3.59,
            3.252,
            2.543,
            4.779,
            2.653,
            4.367,
            3.54,
            3.625,
            5.486
        ],
        "torch.compile": [
            3.84,
            5.34,
            4.46,
            3.79,
            3.39,
            5.53,
            3.39,
            5.49,
            4.55,
            4.46,
            6.29
        ],
        "kv_cache_profiling": [
            9.2,
            11.99,
            9.42,
            8.24,
            7.17,
            12.49,
            7.21,
            11.22,
            9.31,
            9.23,
            13.66
        ],
        "graph_capturing": [
            1.15,
            1.44,
            1.12,
            0.85,
            0.77,
            1.48,
            0.97,
            1.28,
            0.97,
            1.13,
            1.41
        ],
        "init_engine": [
            10.55,
            13.66,
            10.76,
            9.41,
            8.15,
            14.2,
            8.39,
            12.73,
            10.55,
            10.57,
            15.31
        ],
        "tokenizer_init": [
            0.49,
            0.32,
            0.3,
            0.57,
            0.45,
            0.48,
            0.47,
            0.47,
            0.46,
            0.4,
            0.41
        ],
        "total_time": [
            24.298284999999996,
            28.953824,
            24.285422,
            22.206459000000002,
            20.211980999999998,
            30.563315999999997,
            20.851347999999998,
            25.879226,
            24.692939000000003,
            24.079051999999997,
            29.656485
        ],
        "actual_total_time": [
            25.761,
            29.907,
            25.198,
            23.307,
            21.245,
            31.652,
            21.911,
            26.949,
            25.882,
            25.124,
            30.671
        ]
    }
}