{
    "labels": [
        "output_model_falcon-7b.txt",
        "output_model_llama2-13b-hf.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_llama3-3b.txt",
        "output_model_qwen-0.5b.txt",
        "output_model_qwen-14b.txt",
        "output_model_qwen-1.8b.txt",
        "output_model_qwen-4b.txt",
        "output_model_qwen-7b.txt",
        "output_model_yi-6b.txt",
        "output_model_yi-9b.txt"
    ],
    "data": {
        "detect_platfrom": [
            0.34,
            0.354,
            0.338,
            0.502,
            0.342,
            0.342,
            0.508,
            0.503,
            0.506,
            0.511,
            0.448
        ],
        "llm_imports": [
            1.238,
            1.265,
            1.383,
            1.269,
            1.423,
            1.43,
            1.278,
            1.268,
            1.285,
            1.279,
            1.326
        ],
        "get_model_info": [
            6.955,
            6.622,
            6.707,
            6.732,
            6.826,
            6.757,
            6.819,
            6.732,
            7.931,
            6.856,
            6.683
        ],
        "worker_init": [
            2.23,
            2.069,
            2.04,
            2.239,
            2.383,
            2.264,
            2.342,
            2.123,
            2.165,
            2.124,
            2.174
        ],
        "framework_bootstrap": [
            10.763,
            10.309999999999999,
            10.468,
            10.742,
            10.974,
            10.793,
            10.947000000000001,
            10.626000000000001,
            11.887,
            10.770000000000001,
            10.631
        ],
        "load_weights": [
            2.21,
            3.82,
            1.9,
            1.04,
            0.15,
            4.96,
            0.65,
            1.13,
            2.16,
            2.14,
            2.49
        ],
        "model_init": [
            0.1,
            0.11,
            0.1,
            0.12,
            0.09,
            0.11,
            0.1,
            0.11,
            0.11,
            0.11,
            0.12
        ],
        "model_loading": [
            2.866757,
            4.566489,
            2.564651,
            2.044354,
            3.222389,
            5.603157,
            1.309268,
            1.770231,
            2.822641,
            2.789978,
            3.132101
        ],
        "dynamo_transform_time": [
            3.85,
            5.37,
            4.41,
            3.77,
            3.4,
            5.46,
            3.4,
            5.49,
            4.54,
            4.47,
            6.26
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_cached": [
            3.265,
            4.538,
            3.511,
            3.221,
            2.66,
            4.503,
            2.587,
            4.549,
            3.559,
            3.557,
            5.381
        ],
        "torch.compile": [
            3.85,
            5.37,
            4.41,
            3.77,
            3.4,
            5.46,
            3.4,
            5.49,
            4.54,
            4.47,
            6.26
        ],
        "kv_cache_profiling": [
            1.955,
            2.251999999999999,
            1.198999999999999,
            1.4290000000000003,
            1.2399999999999993,
            2.1569999999999983,
            1.2030000000000003,
            1.5009999999999977,
            1.2110000000000003,
            1.2030000000000012,
            1.7490000000000006
        ],
        "graph_capturing": [
            1.18,
            1.44,
            0.92,
            1.05,
            0.97,
            1.45,
            0.81,
            1.28,
            1.15,
            1.14,
            1.42
        ],
        "init_engine": [
            10.47,
            13.83,
            10.31,
            9.68,
            8.47,
            13.79,
            8.44,
            13.04,
            10.76,
            10.69,
            15.05
        ],
        "tokenizer_init": [
            0.37,
            0.38,
            0.32,
            0.5,
            0.48,
            0.48,
            0.47,
            0.48,
            0.48,
            0.41,
            0.41
        ],
        "total_time": [
            24.469757,
            29.086488999999997,
            23.662651,
            22.966354000000003,
            23.146389000000003,
            30.666157,
            21.166268,
            25.916231,
            25.949641000000003,
            24.659978,
            29.223101000000003
        ],
        "actual_total_time": [
            26.003,
            30.116,
            24.578,
            24.097,
            24.271,
            31.787,
            22.294,
            27.011,
            27.069,
            25.707,
            30.251
        ]
    }
}