{
    "labels": [
        "output_model_falcon-7b.txt",
        "output_model_llama2-13b-hf.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_llama3-3b.txt",
        "output_model_qwen-0.5b.txt",
        "output_model_qwen-14b.txt",
        "output_model_qwen-1.8b.txt",
        "output_model_qwen-4b.txt",
        "output_model_qwen-7b.txt",
        "output_model_yi-6b.txt",
        "output_model_yi-9b.txt"
    ],
    "data": {
        "detect_platform": [
            0.343,
            0.343,
            0.343,
            0.342,
            0.345,
            0.347,
            0.345,
            0.516,
            0.512,
            0.449,
            0.421
        ],
        "llm_imports": [
            1.215,
            1.21,
            1.397,
            1.487,
            1.418,
            1.392,
            1.243,
            1.263,
            1.272,
            1.304,
            1.262
        ],
        "get_model_info": [
            7.045,
            7.114,
            9.277,
            6.788,
            6.881,
            6.776,
            6.966,
            6.647,
            6.992,
            7.997,
            6.733
        ],
        "worker_init": [
            2.223,
            2.256,
            2.129,
            2.334,
            2.288,
            2.151,
            2.212,
            2.226,
            2.097,
            2.168,
            2.202
        ],
        "framework_bootstrap": [
            10.826,
            10.923,
            13.145999999999999,
            10.951,
            10.932,
            10.666,
            10.766,
            10.652000000000001,
            10.873,
            11.918,
            10.618
        ],
        "load_weights": [
            2.21,
            3.81,
            1.92,
            1.06,
            0.15,
            4.53,
            0.55,
            1.16,
            2.19,
            1.73,
            2.84
        ],
        "model_init": [
            0.1,
            0.11,
            0.1,
            0.12,
            0.09,
            0.12,
            0.1,
            0.11,
            0.1,
            0.1,
            0.12
        ],
        "model_loading": [
            2.988402,
            4.450484,
            2.667478,
            2.091709,
            2.043702,
            5.166585,
            1.171478,
            1.751191,
            2.913823,
            2.391299,
            3.480365
        ],
        "dynamo_transform_time": [
            3.86,
            5.37,
            4.4,
            3.77,
            3.4,
            5.44,
            3.4,
            5.48,
            4.54,
            4.44,
            6.27
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_cached": [
            3.35,
            4.419,
            3.566,
            3.197,
            2.65,
            4.484,
            2.798,
            4.545,
            3.509,
            3.697,
            5.462
        ],
        "torch.compile": [
            3.86,
            5.37,
            4.4,
            3.77,
            3.4,
            5.44,
            3.4,
            5.48,
            4.54,
            4.44,
            6.27
        ],
        "kv_cache_profiling": [
            2.0300000000000002,
            2.171000000000001,
            1.2139999999999995,
            1.392999999999999,
            1.29,
            2.136000000000001,
            1.1819999999999995,
            1.3849999999999998,
            1.1910000000000007,
            1.1630000000000003,
            1.7880000000000003
        ],
        "graph_capturing": [
            1.14,
            1.43,
            1.13,
            1.05,
            0.96,
            1.51,
            0.96,
            1.28,
            1.13,
            0.95,
            1.59
        ],
        "init_engine": [
            10.6,
            13.61,
            10.53,
            9.63,
            8.51,
            13.94,
            8.55,
            12.91,
            10.65,
            10.47,
            15.4
        ],
        "tokenizer_init": [
            0.37,
            0.33,
            0.56,
            0.58,
            0.54,
            0.48,
            0.48,
            0.46,
            0.48,
            0.41,
            0.41
        ],
        "total_time": [
            24.784402000000004,
            29.313484,
            26.903477999999996,
            23.252709,
            22.025702,
            30.252585,
            20.967478000000003,
            25.773191000000004,
            24.916822999999997,
            25.189299000000002,
            29.908365
        ],
        "actual_total_time": [
            26.376,
            30.275,
            27.914,
            24.428,
            23.154,
            31.404,
            22.032,
            26.864,
            25.97,
            26.205,
            31.044
        ]
    }
}