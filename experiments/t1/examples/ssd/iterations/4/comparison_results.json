{
    "labels": [
        "output_model_falcon-7b.txt",
        "output_model_llama2-13b-hf.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_llama3-3b.txt",
        "output_model_qwen-0.5b.txt",
        "output_model_qwen-14b.txt",
        "output_model_qwen-1.8b.txt",
        "output_model_qwen-4b.txt",
        "output_model_qwen-7b.txt",
        "output_model_yi-6b.txt",
        "output_model_yi-9b.txt"
    ],
    "data": {
        "load_weights": [
            3.49,
            6.03,
            3.4,
            1.4,
            0.22,
            6.33,
            0.81,
            1.69,
            3.37,
            2.67,
            3.85
        ],
        "model_init": [
            0.13,
            0.11,
            0.11,
            0.12,
            0.09,
            0.39,
            0.1,
            0.43,
            0.35,
            0.28,
            0.14
        ],
        "model_loading": [
            4.169148,
            6.803025,
            4.043069,
            2.060656,
            0.894552,
            7.253154,
            1.509216,
            2.643549,
            4.252403,
            3.590315,
            4.516103
        ],
        "dynamo_transform_time": [
            4.08,
            5.36,
            4.45,
            3.77,
            3.36,
            5.42,
            3.37,
            5.4,
            4.45,
            4.42,
            6.23
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_cached": [
            3.678,
            5.07,
            3.845,
            3.418,
            2.806,
            5.154,
            2.945,
            5.843,
            4.173,
            4.055,
            5.914
        ],
        "torch.compile": [
            4.08,
            5.36,
            4.45,
            3.77,
            3.36,
            5.42,
            3.37,
            5.4,
            4.45,
            4.42,
            6.23
        ],
        "kv_cache_profiling": [
            10.26,
            12.76,
            9.59,
            8.67,
            7.34,
            12.72,
            7.62,
            12.87,
            10.11,
            9.67,
            13.87
        ],
        "graph_capturing": [
            1.33,
            1.62,
            1.27,
            1.19,
            1.11,
            2.11,
            0.79,
            1.41,
            1.44,
            0.97,
            1.59
        ],
        "init_engine": [
            11.92,
            14.62,
            11.09,
            10.09,
            8.66,
            15.06,
            8.65,
            14.54,
            11.77,
            11.16,
            15.95
        ],
        "tokenizer_init": [
            0.39,
            0.34,
            0.33,
            0.53,
            0.51,
            0.51,
            0.5,
            0.5,
            0.51,
            0.42,
            0.42
        ],
        "total_time": [
            16.479148000000002,
            21.763025,
            15.463068999999999,
            12.680655999999999,
            10.064552,
            22.823154000000002,
            10.659216,
            17.683549,
            16.532403000000002,
            15.170315,
            20.886103000000002
        ],
        "actual_total_time": [
            27.63,
            31.79,
            25.98,
            22.95,
            20.32,
            32.59,
            20.5,
            27.6,
            26.31,
            24.94,
            31.72
        ]
    }
}