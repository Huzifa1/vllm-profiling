{
    "labels": [
        "output_model_falcon-7b.txt",
        "output_model_llama2-13b-hf.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_llama3-3b.txt",
        "output_model_qwen-0.5b.txt",
        "output_model_qwen-14b.txt",
        "output_model_qwen-1.8b.txt",
        "output_model_qwen-4b.txt",
        "output_model_qwen-7b.txt",
        "output_model_yi-6b.txt",
        "output_model_yi-9b.txt"
    ],
    "data": {
        "detect_platfrom": [
            1.0,
            1.0,
            1.0,
            0.0,
            1.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        "llm_imports": [
            1.0,
            1.0,
            1.0,
            2.0,
            1.0,
            2.0,
            1.0,
            1.0,
            1.0,
            2.0,
            1.0
        ],
        "get_model_info": [
            8.0,
            7.0,
            7.0,
            6.0,
            8.0,
            7.0,
            7.0,
            7.0,
            7.0,
            6.0,
            7.0
        ],
        "worker_init": [
            2.0,
            2.0,
            2.0,
            3.0,
            3.0,
            3.0,
            3.0,
            2.0,
            2.0,
            2.0,
            3.0
        ],
        "framework_bootstrap": [
            12.0,
            11.0,
            11.0,
            11.0,
            13.0,
            12.0,
            11.0,
            10.0,
            10.0,
            10.0,
            11.0
        ],
        "load_weights": [
            3.55,
            6.01,
            2.99,
            1.59,
            0.21,
            6.24,
            0.82,
            1.69,
            3.38,
            2.66,
            4.27
        ],
        "model_init": [
            0.14,
            0.11,
            0.11,
            0.13,
            0.09,
            0.11,
            0.24,
            0.11,
            0.2,
            0.34,
            0.13
        ],
        "model_loading": [
            4.26091,
            6.697757,
            3.649398,
            2.490517,
            0.833898,
            6.902473,
            1.602672,
            2.339067,
            4.2184,
            3.533642,
            4.98284
        ],
        "dynamo_transform_time": [
            4.09,
            5.39,
            4.39,
            3.8,
            3.36,
            5.42,
            3.38,
            5.46,
            4.57,
            4.41,
            6.44
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_cached": [
            3.98,
            4.796,
            3.663,
            3.693,
            3.068,
            5.086,
            2.85,
            5.655,
            3.918,
            4.535,
            5.978
        ],
        "torch.compile": [
            4.09,
            5.39,
            4.39,
            3.8,
            3.36,
            5.42,
            3.38,
            5.46,
            4.57,
            4.41,
            6.44
        ],
        "kv_cache_profiling": [
            2.3499999999999996,
            2.234,
            1.2670000000000012,
            1.286999999999999,
            1.2620000000000005,
            2.4339999999999993,
            1.3199999999999994,
            1.4749999999999996,
            1.3420000000000005,
            1.3449999999999989,
            2.0520000000000014
        ],
        "graph_capturing": [
            1.75,
            2.33,
            1.31,
            1.11,
            1.03,
            1.64,
            1.09,
            1.64,
            1.32,
            1.5,
            1.61
        ],
        "init_engine": [
            12.42,
            15.07,
            10.85,
            10.35,
            8.92,
            14.83,
            8.84,
            14.45,
            11.49,
            12.04,
            16.33
        ],
        "tokenizer_init": [
            0.63,
            0.33,
            0.34,
            0.55,
            0.51,
            0.49,
            0.51,
            0.51,
            0.52,
            0.41,
            0.42
        ],
        "total_time": [
            29.310909999999996,
            33.097757,
            25.839398,
            24.390517,
            23.263898,
            34.222473,
            21.952672000000003,
            27.299067,
            26.228399999999997,
            25.983642,
            32.732839999999996
        ],
        "actual_total_time": [
            31.0,
            34.0,
            26.0,
            26.0,
            23.0,
            34.0,
            23.0,
            29.0,
            28.0,
            28.0,
            33.0
        ]
    }
}