{
    "labels": [
        "output_model_falcon-7b.txt",
        "output_model_llama2-13b-hf.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_llama3-3b.txt",
        "output_model_qwen-0.5b.txt",
        "output_model_qwen-14b.txt",
        "output_model_qwen-1.8b.txt",
        "output_model_qwen-4b.txt",
        "output_model_qwen-7b.txt",
        "output_model_yi-6b.txt",
        "output_model_yi-9b.txt"
    ],
    "data": {
        "detect_platfrom": [
            0.567,
            0.389,
            0.574,
            0.386,
            0.387,
            0.58,
            0.39,
            0.575,
            0.388,
            0.51,
            0.515
        ],
        "llm_imports": [
            1.512,
            1.494,
            1.305,
            1.507,
            1.251,
            1.332,
            1.309,
            1.313,
            1.254,
            1.365,
            1.371
        ],
        "get_model_info": [
            7.416,
            6.917,
            6.989,
            6.926,
            6.945,
            6.922,
            6.991,
            6.91,
            7.357,
            7.078,
            7.173
        ],
        "worker_init": [
            2.501,
            2.236,
            2.356,
            2.305,
            2.283,
            2.188,
            2.356,
            2.378,
            2.418,
            2.192,
            2.166
        ],
        "framework_bootstrap": [
            11.996,
            11.036000000000001,
            11.224,
            11.123999999999999,
            10.866,
            11.022,
            11.046,
            11.176,
            11.417000000000002,
            11.145,
            11.225000000000001
        ],
        "load_weights": [
            3.55,
            5.99,
            2.98,
            1.6,
            0.2,
            6.26,
            0.81,
            1.72,
            3.37,
            2.65,
            3.88
        ],
        "model_init": [
            0.14,
            0.11,
            0.1,
            0.13,
            0.09,
            0.11,
            0.1,
            0.11,
            0.11,
            0.1,
            0.12
        ],
        "model_loading": [
            4.226521,
            6.749446,
            3.92982,
            2.301806,
            0.821976,
            6.924807,
            1.520864,
            2.573744,
            4.055507,
            3.283911,
            4.539175
        ],
        "dynamo_transform_time": [
            4.07,
            5.26,
            4.38,
            3.73,
            3.29,
            5.29,
            3.36,
            5.45,
            4.49,
            4.33,
            6.16
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_cached": [
            3.333,
            4.66,
            3.632,
            3.256,
            2.516,
            4.641,
            2.744,
            4.631,
            3.629,
            3.689,
            5.461
        ],
        "torch.compile": [
            4.07,
            5.26,
            4.38,
            3.73,
            3.29,
            5.29,
            3.36,
            5.45,
            4.49,
            4.33,
            6.16
        ],
        "kv_cache_profiling": [
            9.72,
            12.08,
            9.4,
            8.18,
            7.04,
            12.09,
            7.28,
            11.53,
            9.33,
            9.15,
            13.37
        ],
        "graph_capturing": [
            1.19,
            1.48,
            1.12,
            1.08,
            0.76,
            1.71,
            0.79,
            1.3,
            1.18,
            1.15,
            1.46
        ],
        "init_engine": [
            11.16,
            13.88,
            10.79,
            9.46,
            8.0,
            14.02,
            8.46,
            13.06,
            10.72,
            10.54,
            15.19
        ],
        "tokenizer_init": [
            0.38,
            0.34,
            0.34,
            0.62,
            0.51,
            0.52,
            0.49,
            0.53,
            0.57,
            0.44,
            0.43
        ],
        "total_time": [
            27.762521,
            32.005446000000006,
            26.28382,
            23.505806,
            20.197976,
            32.486807,
            21.516863999999998,
            27.339744000000003,
            26.762507000000003,
            25.408911,
            31.384175
        ],
        "actual_total_time": [
            29.312,
            32.996,
            27.385,
            24.696,
            21.302,
            33.682,
            22.662,
            28.508,
            28.081,
            26.476,
            32.46
        ]
    }
}