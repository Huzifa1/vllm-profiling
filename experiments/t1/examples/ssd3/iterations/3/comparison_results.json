{
    "labels": [
        "output_model_falcon-7b.txt",
        "output_model_llama2-13b-hf.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_llama3-3b.txt",
        "output_model_qwen-0.5b.txt",
        "output_model_qwen-14b.txt",
        "output_model_qwen-1.8b.txt",
        "output_model_qwen-4b.txt",
        "output_model_qwen-7b.txt",
        "output_model_yi-6b.txt",
        "output_model_yi-9b.txt"
    ],
    "data": {
        "detect_platform": [
            0.541,
            0.389,
            0.575,
            0.385,
            0.388,
            0.566,
            0.391,
            0.576,
            0.515,
            0.51,
            0.512
        ],
        "llm_imports": [
            1.527,
            1.247,
            1.302,
            1.485,
            1.438,
            1.305,
            1.477,
            1.316,
            1.371,
            1.364,
            1.388
        ],
        "get_model_info": [
            7.706,
            6.9,
            6.853,
            6.965,
            6.958,
            6.916,
            7.011,
            7.003,
            7.0,
            6.982,
            7.046
        ],
        "worker_init": [
            2.54,
            2.21,
            2.221,
            2.325,
            2.15,
            2.423,
            2.229,
            2.169,
            2.163,
            2.191,
            2.176
        ],
        "framework_bootstrap": [
            12.314,
            10.746000000000002,
            10.951,
            11.16,
            10.934000000000001,
            11.21,
            11.108,
            11.064,
            11.049,
            11.047,
            11.122
        ],
        "load_weights": [
            3.5,
            5.9,
            2.93,
            1.43,
            0.22,
            6.27,
            0.84,
            1.74,
            3.37,
            2.67,
            3.85
        ],
        "model_init": [
            0.13,
            0.11,
            0.1,
            0.13,
            0.09,
            0.11,
            0.09,
            0.11,
            0.1,
            0.11,
            0.12
        ],
        "model_loading": [
            4.277233,
            6.583948,
            3.579725,
            2.103951,
            0.868428,
            6.912133,
            1.559256,
            2.384546,
            4.011482,
            3.292243,
            4.512983
        ],
        "dynamo_transform_time": [
            4.03,
            5.37,
            4.29,
            3.76,
            3.41,
            5.4,
            3.45,
            5.39,
            4.48,
            4.36,
            6.19
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_cached": [
            3.345,
            4.61,
            3.461,
            3.31,
            2.637,
            4.624,
            2.744,
            4.484,
            3.693,
            3.621,
            5.449
        ],
        "torch.compile": [
            4.03,
            5.37,
            4.29,
            3.76,
            3.41,
            5.4,
            3.45,
            5.39,
            4.48,
            4.36,
            6.19
        ],
        "kv_cache_profiling": [
            1.9949999999999992,
            2.17,
            1.1989999999999998,
            1.4100000000000001,
            1.2329999999999997,
            2.2659999999999982,
            1.2659999999999991,
            1.3960000000000008,
            1.327,
            1.1790000000000003,
            1.7010000000000005
        ],
        "graph_capturing": [
            1.12,
            1.46,
            1.12,
            1.07,
            0.78,
            1.52,
            0.79,
            1.29,
            1.16,
            1.14,
            1.46
        ],
        "init_engine": [
            10.7,
            13.92,
            10.29,
            9.77,
            8.26,
            14.04,
            8.47,
            12.79,
            10.87,
            10.52,
            15.19
        ],
        "tokenizer_init": [
            0.38,
            0.36,
            0.34,
            0.53,
            0.51,
            0.52,
            0.5,
            0.5,
            0.52,
            0.43,
            0.44
        ],
        "total_time": [
            27.671232999999997,
            31.609948000000003,
            25.160725,
            23.563951000000003,
            20.572428000000002,
            32.682133,
            21.637256,
            26.738546,
            26.450481999999997,
            25.289243,
            31.264983
        ],
        "actual_total_time": [
            29.163,
            32.661,
            26.136,
            24.845,
            21.741,
            33.881,
            22.826,
            27.816,
            27.596,
            26.341,
            32.366
        ]
    }
}