{
    "labels": [
        "output_model_falcon-7b.txt",
        "output_model_llama2-13b-hf.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_llama3-3b.txt",
        "output_model_qwen-0.5b.txt",
        "output_model_qwen-14b.txt",
        "output_model_qwen-1.8b.txt",
        "output_model_qwen-4b.txt",
        "output_model_qwen-7b.txt",
        "output_model_yi-6b.txt",
        "output_model_yi-9b.txt"
    ],
    "data": {
        "detect_platfrom": [
            0.519,
            0.454,
            0.398,
            0.529,
            0.47,
            0.581,
            0.391,
            0.342,
            0.387,
            0.575,
            0.392
        ],
        "llm_imports": [
            1.471,
            1.357,
            1.268,
            1.362,
            1.317,
            1.314,
            1.454,
            1.417,
            1.44,
            1.328,
            1.482
        ],
        "get_model_info": [
            7.31,
            7.007,
            6.9,
            7.026,
            6.896,
            6.948,
            7.21,
            6.982,
            7.018,
            7.019,
            6.979
        ],
        "worker_init": [
            2.449,
            2.207,
            2.237,
            2.29,
            2.164,
            2.274,
            2.293,
            2.384,
            2.23,
            2.219,
            2.196
        ],
        "framework_bootstrap": [
            11.749,
            11.024999999999999,
            10.803,
            11.207,
            10.847,
            11.117,
            11.347999999999999,
            11.125,
            11.075,
            11.141,
            11.049
        ],
        "load_weights": [
            3.43,
            6.28,
            3.06,
            1.41,
            0.21,
            6.29,
            0.82,
            2.02,
            3.37,
            2.66,
            3.9
        ],
        "model_init": [
            0.13,
            0.12,
            0.11,
            0.13,
            0.09,
            0.12,
            0.1,
            0.11,
            0.1,
            0.1,
            0.12
        ],
        "model_loading": [
            4.130774,
            6.924908,
            3.771371,
            2.070419,
            0.846137,
            6.925628,
            1.445754,
            2.689995,
            4.085417,
            3.301083,
            4.572782
        ],
        "dynamo_transform_time": [
            4.05,
            5.29,
            4.34,
            3.79,
            3.31,
            5.38,
            3.36,
            5.44,
            4.47,
            4.29,
            6.17
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_cached": [
            3.263,
            4.703,
            3.304,
            3.352,
            2.549,
            4.672,
            2.735,
            4.59,
            3.693,
            3.705,
            5.666
        ],
        "torch.compile": [
            4.05,
            5.29,
            4.34,
            3.79,
            3.31,
            5.38,
            3.36,
            5.44,
            4.47,
            4.29,
            6.17
        ],
        "kv_cache_profiling": [
            9.56,
            12.19,
            8.82,
            8.36,
            6.99,
            12.22,
            7.25,
            11.38,
            9.34,
            9.15,
            13.77
        ],
        "graph_capturing": [
            1.18,
            1.63,
            1.14,
            0.85,
            0.77,
            1.5,
            0.79,
            1.29,
            1.18,
            1.15,
            1.44
        ],
        "init_engine": [
            10.97,
            14.04,
            10.18,
            9.41,
            8.08,
            14.08,
            8.42,
            12.95,
            10.73,
            10.51,
            15.44
        ],
        "tokenizer_init": [
            0.39,
            0.34,
            0.34,
            0.53,
            0.5,
            1.53,
            0.5,
            0.5,
            0.5,
            0.42,
            0.44
        ],
        "total_time": [
            27.239774000000004,
            32.329908,
            25.094371,
            23.217419,
            20.273137,
            33.652628,
            21.713754,
            27.264995,
            26.390417,
            25.372083000000003,
            31.501782000000002
        ],
        "actual_total_time": [
            28.806,
            33.268,
            26.074,
            24.36,
            21.417,
            34.899,
            22.856,
            28.418,
            27.691,
            26.429,
            32.562
        ]
    }
}