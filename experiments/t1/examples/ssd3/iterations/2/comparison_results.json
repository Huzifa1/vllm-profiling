{
    "labels": [
        "output_model_falcon-7b.txt",
        "output_model_llama2-13b-hf.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_llama3-3b.txt",
        "output_model_qwen-0.5b.txt",
        "output_model_qwen-14b.txt",
        "output_model_qwen-1.8b.txt",
        "output_model_qwen-4b.txt",
        "output_model_qwen-7b.txt",
        "output_model_yi-6b.txt",
        "output_model_yi-9b.txt"
    ],
    "data": {
        "detect_platfrom": [
            0.543,
            0.508,
            0.39,
            0.58,
            0.39,
            0.516,
            0.39,
            0.581,
            0.507,
            0.385,
            0.573
        ],
        "llm_imports": [
            1.503,
            1.36,
            1.459,
            1.34,
            1.477,
            1.37,
            1.503,
            1.313,
            1.306,
            1.445,
            1.31
        ],
        "get_model_info": [
            7.448,
            6.914,
            7.063,
            6.916,
            7.337,
            6.92,
            6.958,
            6.954,
            6.894,
            7.123,
            7.05
        ],
        "worker_init": [
            2.502,
            2.212,
            2.386,
            2.419,
            3.048,
            2.4,
            2.446,
            2.445,
            2.154,
            2.254,
            2.193
        ],
        "framework_bootstrap": [
            11.995999999999999,
            10.994,
            11.297999999999998,
            11.255,
            12.252,
            11.206000000000001,
            11.296999999999999,
            11.293,
            10.861,
            11.206999999999999,
            11.126
        ],
        "load_weights": [
            3.5,
            5.84,
            2.97,
            1.63,
            0.21,
            6.24,
            0.81,
            1.73,
            3.34,
            2.66,
            3.91
        ],
        "model_init": [
            0.13,
            0.11,
            0.11,
            0.14,
            0.25,
            0.11,
            0.1,
            0.11,
            0.1,
            0.11,
            0.12
        ],
        "model_loading": [
            4.209013,
            6.477197,
            3.623806,
            2.291821,
            1.180265,
            6.897421,
            1.689632,
            2.584539,
            3.982328,
            3.583758,
            4.563008
        ],
        "dynamo_transform_time": [
            4.06,
            5.2,
            4.38,
            3.8,
            3.36,
            5.33,
            3.35,
            5.35,
            4.43,
            4.32,
            6.14
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_cached": [
            3.453,
            4.385,
            3.624,
            3.22,
            2.554,
            4.677,
            2.675,
            4.456,
            3.67,
            3.708,
            5.422
        ],
        "torch.compile": [
            4.06,
            5.2,
            4.38,
            3.8,
            3.36,
            5.33,
            3.35,
            5.35,
            4.43,
            4.32,
            6.14
        ],
        "kv_cache_profiling": [
            9.78,
            11.78,
            9.2,
            8.41,
            7.05,
            12.28,
            7.12,
            11.14,
            9.3,
            9.22,
            13.28
        ],
        "graph_capturing": [
            1.16,
            1.47,
            0.93,
            1.06,
            1.0,
            1.5,
            0.93,
            1.27,
            1.15,
            0.93,
            1.46
        ],
        "init_engine": [
            11.17,
            13.48,
            10.35,
            9.68,
            8.26,
            13.99,
            8.25,
            12.63,
            10.66,
            10.51,
            15.15
        ],
        "tokenizer_init": [
            0.38,
            0.45,
            0.35,
            0.53,
            0.52,
            0.53,
            0.51,
            0.53,
            0.5,
            0.43,
            0.43
        ],
        "total_time": [
            27.755012999999995,
            31.401197,
            25.621806,
            23.756821000000002,
            22.212265,
            32.623421,
            21.746632,
            27.037539000000002,
            26.003328,
            25.730757999999998,
            31.269008
        ],
        "actual_total_time": [
            29.322,
            32.356,
            26.601,
            24.974,
            23.327,
            33.77,
            22.824,
            28.192,
            27.161,
            26.805,
            32.337
        ]
    }
}