{
    "labels": [
        "output_model_falcon-7b.txt",
        "output_model_llama2-13b-hf.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_llama3-3b.txt",
        "output_model_qwen-0.5b.txt",
        "output_model_qwen-14b.txt",
        "output_model_qwen-1.8b.txt",
        "output_model_qwen-4b.txt",
        "output_model_qwen-7b.txt",
        "output_model_yi-6b.txt",
        "output_model_yi-9b.txt"
    ],
    "data": {
        "detect_platfrom": [
            0.545,
            0.385,
            0.389,
            0.509,
            0.569,
            0.389,
            0.512,
            0.574,
            0.513,
            0.571,
            0.51
        ],
        "llm_imports": [
            1.5,
            1.253,
            1.497,
            1.365,
            1.32,
            1.468,
            1.361,
            1.31,
            1.312,
            1.323,
            1.356
        ],
        "get_model_info": [
            7.437,
            6.845,
            7.026,
            6.875,
            7.043,
            7.007,
            6.914,
            6.997,
            7.121,
            6.963,
            6.896
        ],
        "worker_init": [
            2.493,
            2.215,
            2.235,
            2.193,
            2.385,
            2.386,
            2.413,
            2.441,
            2.433,
            2.171,
            2.22
        ],
        "framework_bootstrap": [
            11.975,
            10.698,
            11.146999999999998,
            10.942,
            11.317,
            11.25,
            11.2,
            11.322,
            11.379000000000001,
            11.027999999999999,
            10.982000000000001
        ],
        "load_weights": [
            3.46,
            5.93,
            2.99,
            1.39,
            0.21,
            6.27,
            0.82,
            1.74,
            3.4,
            2.65,
            3.88
        ],
        "model_init": [
            0.13,
            0.11,
            0.11,
            0.12,
            0.09,
            0.11,
            0.1,
            0.11,
            0.11,
            0.1,
            0.12
        ],
        "model_loading": [
            4.129565,
            6.577678,
            3.622458,
            2.022256,
            0.855947,
            6.990777,
            1.500688,
            2.469246,
            4.057937,
            3.353321,
            4.528345
        ],
        "dynamo_transform_time": [
            4.06,
            5.29,
            4.33,
            3.75,
            3.36,
            5.47,
            3.36,
            5.44,
            4.51,
            4.34,
            6.07
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_cached": [
            3.458,
            4.524,
            3.328,
            3.252,
            2.693,
            4.629,
            2.736,
            4.305,
            3.6,
            3.713,
            5.421
        ],
        "torch.compile": [
            4.06,
            5.29,
            4.33,
            3.75,
            3.36,
            5.47,
            3.36,
            5.44,
            4.51,
            4.34,
            6.07
        ],
        "kv_cache_profiling": [
            9.52,
            11.96,
            8.84,
            8.24,
            7.43,
            12.28,
            7.27,
            11.14,
            9.34,
            9.19,
            13.19
        ],
        "graph_capturing": [
            1.2,
            1.48,
            1.15,
            0.99,
            0.99,
            1.52,
            0.79,
            1.3,
            1.19,
            1.15,
            1.63
        ],
        "init_engine": [
            10.92,
            13.67,
            10.22,
            9.44,
            8.64,
            14.03,
            8.46,
            12.67,
            10.76,
            10.57,
            15.05
        ],
        "tokenizer_init": [
            0.39,
            0.34,
            0.34,
            0.54,
            0.51,
            0.53,
            0.51,
            0.51,
            0.55,
            0.49,
            0.43
        ],
        "total_time": [
            27.414565000000003,
            31.285678,
            25.329458,
            22.944256,
            21.322947000000003,
            32.800777000000004,
            21.670688000000002,
            26.971246,
            26.746937,
            25.441321,
            30.990345
        ],
        "actual_total_time": [
            28.921,
            32.259,
            26.332,
            24.098,
            22.555,
            33.953,
            22.828,
            28.168,
            28.078,
            26.492,
            32.052
        ]
    }
}