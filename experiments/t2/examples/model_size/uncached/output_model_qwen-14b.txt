DEBUG 10-06 14:56:36 [__init__.py:28] No plugins for group vllm.platform_plugins found.
DEBUG 10-06 14:56:36 [__init__.py:34] Checking if TPU platform is available.
DEBUG 10-06 14:56:36 [__init__.py:52] TPU platform is not available because: No module named 'libtpu'
DEBUG 10-06 14:56:36 [__init__.py:58] Checking if CUDA platform is available.
DEBUG 10-06 14:56:36 [__init__.py:78] Confirmed CUDA platform is available.
DEBUG 10-06 14:56:36 [__init__.py:106] Checking if ROCm platform is available.
DEBUG 10-06 14:56:36 [__init__.py:120] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 10-06 14:56:36 [__init__.py:127] Checking if XPU platform is available.
DEBUG 10-06 14:56:36 [__init__.py:146] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 10-06 14:56:36 [__init__.py:153] Checking if CPU platform is available.
DEBUG 10-06 14:56:36 [__init__.py:175] Checking if Neuron platform is available.
DEBUG 10-06 14:56:36 [__init__.py:58] Checking if CUDA platform is available.
DEBUG 10-06 14:56:36 [__init__.py:78] Confirmed CUDA platform is available.
INFO 10-06 14:56:36 [__init__.py:241] Automatically detected platform cuda.
DEBUG 10-06 14:56:37 [__init__.py:36] Available plugins for group vllm.general_plugins:
DEBUG 10-06 14:56:37 [__init__.py:38] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
DEBUG 10-06 14:56:37 [__init__.py:41] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
INFO 10-06 14:56:42 [__init__.py:711] Resolved architecture: Qwen2ForCausalLM
INFO 10-06 14:56:42 [__init__.py:1750] Using max model len 32768
INFO 10-06 14:56:42 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=2048.
DEBUG 10-06 14:56:42 [llm_engine.py:154] Enabling multiprocessing for LLMEngine.
INFO 10-06 14:56:44 [llm_engine.py:95] NEW: Init Tokenizer took 1.64 seconds
[1;36m(EngineCore_0 pid=150328)[0;0m INFO 10-06 14:56:44 [core.py:636] Waiting for init message from front-end.
DEBUG 10-06 14:56:44 [utils.py:831] HELLO from local core engine process 0.
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:44 [core.py:644] Received init message: EngineHandshakeMetadata(addresses=EngineZmqAddresses(inputs=['ipc:///tmp/4f71913f-d96d-4750-928a-162e2721964c'], outputs=['ipc:///tmp/9c90e816-3a03-4f83-ac55-a5d0a6a79704'], coordinator_input=None, coordinator_output=None, frontend_stats_publish_address=None), parallel_config={'data_parallel_master_ip': '127.0.0.1', 'data_parallel_master_port': 0, 'data_parallel_size': 1})
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:44 [core.py:481] Has DP Coordinator: False, stats publish address: None
[1;36m(EngineCore_0 pid=150328)[0;0m INFO 10-06 14:56:44 [core.py:74] Initializing a V1 LLM engine (v0.10.1.1) with config: model='Qwen/Qwen1.5-14B', speculative_config=None, tokenizer='Qwen/Qwen1.5-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen1.5-14B, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":1,"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"pass_config":{},"max_capture_size":256,"local_cache_dir":null}
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:45 [decorators.py:139] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama.LlamaModel'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:45 [decorators.py:139] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama_eagle3.LlamaModel'>: ['input_ids', 'positions', 'hidden_states']
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:45 [__init__.py:3073] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f51d48bcb00>
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:45 [__init__.py:3885] enabled custom ops: Counter()
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:45 [__init__.py:3887] disabled custom ops: Counter()
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:45 [parallel_state.py:976] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://9.4.233.84:43655 backend=nccl
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:45 [parallel_state.py:1027] Detected 1 nodes in the distributed environment
[1;36m(EngineCore_0 pid=150328)[0;0m INFO 10-06 14:56:45 [parallel_state.py:1134] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_0 pid=150328)[0;0m WARNING 10-06 14:56:45 [topk_topp_sampler.py:61] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:45 [__init__.py:51] No logitsprocs plugins installed (group vllm.logits_processors).
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:45 [__init__.py:3885] enabled custom ops: Counter()
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:45 [__init__.py:3887] disabled custom ops: Counter()
[1;36m(EngineCore_0 pid=150328)[0;0m INFO 10-06 14:56:45 [gpu_model_runner.py:1953] Starting to load model Qwen/Qwen1.5-14B...
[1;36m(EngineCore_0 pid=150328)[0;0m INFO 10-06 14:56:46 [gpu_model_runner.py:1985] Loading model from scratch...
[1;36m(EngineCore_0 pid=150328)[0;0m INFO 10-06 14:56:46 [cuda.py:328] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:46 [backends.py:39] Using InductorAdaptor
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:46 [__init__.py:3885] enabled custom ops: Counter()
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:46 [__init__.py:3887] disabled custom ops: Counter({'rms_norm': 81, 'column_parallel_linear': 80, 'row_parallel_linear': 80, 'silu_and_mul': 40, 'vocab_parallel_embedding': 2, 'rotary_embedding': 1})
[1;36m(EngineCore_0 pid=150328)[0;0m INFO 10-06 14:56:46 [base_loader.py:48] NEW: Initializing Model took 0.10 seconds
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:46 [base_loader.py:50] Loading weights on cuda ...
[1;36m(EngineCore_0 pid=150328)[0;0m INFO 10-06 14:56:46 [weight_utils.py:296] Using model weights format ['*.safetensors']
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:46 [utils.py:183] Loaded weight lm_head.weight with shape torch.Size([152064, 5120])
[1;36m(EngineCore_0 pid=150328)[0;0m INFO 10-06 14:56:50 [default_loader.py:262] Loading weights took 3.51 seconds
[1;36m(EngineCore_0 pid=150328)[0;0m INFO 10-06 14:56:50 [gpu_model_runner.py:2007] Model loading took 26.4278 GiB and 4.210228 seconds
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:50 [decorators.py:237] Start compiling function <code object forward at 0x5574845989b0, file "/mnt/data/atr/src/huzaifa-vllm-profiling/.vllm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 338>
DEBUG 10-06 14:56:54 [utils.py:750] Waiting for 1 local, 0 remote core engine proc(s) to start.
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:55 [backends.py:501] Traced files (to be considered for compilation cache):
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:55 [backends.py:501] /mnt/data/atr/src/huzaifa-vllm-profiling/.vllm/lib/python3.12/site-packages/torch/_dynamo/polyfills/__init__.py
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:55 [backends.py:501] /mnt/data/atr/src/huzaifa-vllm-profiling/.vllm/lib/python3.12/site-packages/torch/nn/modules/container.py
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:55 [backends.py:501] /mnt/data/atr/src/huzaifa-vllm-profiling/.vllm/lib/python3.12/site-packages/torch/nn/modules/module.py
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:55 [backends.py:501] /mnt/data/atr/src/huzaifa-vllm-profiling/.vllm/lib/python3.12/site-packages/vllm/attention/layer.py
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:55 [backends.py:501] /mnt/data/atr/src/huzaifa-vllm-profiling/.vllm/lib/python3.12/site-packages/vllm/distributed/communication_op.py
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:55 [backends.py:501] /mnt/data/atr/src/huzaifa-vllm-profiling/.vllm/lib/python3.12/site-packages/vllm/distributed/parallel_state.py
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:55 [backends.py:501] /mnt/data/atr/src/huzaifa-vllm-profiling/.vllm/lib/python3.12/site-packages/vllm/model_executor/custom_op.py
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:55 [backends.py:501] /mnt/data/atr/src/huzaifa-vllm-profiling/.vllm/lib/python3.12/site-packages/vllm/model_executor/layers/activation.py
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:55 [backends.py:501] /mnt/data/atr/src/huzaifa-vllm-profiling/.vllm/lib/python3.12/site-packages/vllm/model_executor/layers/layernorm.py
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:55 [backends.py:501] /mnt/data/atr/src/huzaifa-vllm-profiling/.vllm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:55 [backends.py:501] /mnt/data/atr/src/huzaifa-vllm-profiling/.vllm/lib/python3.12/site-packages/vllm/model_executor/layers/rotary_embedding/base.py
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:55 [backends.py:501] /mnt/data/atr/src/huzaifa-vllm-profiling/.vllm/lib/python3.12/site-packages/vllm/model_executor/layers/rotary_embedding/common.py
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:55 [backends.py:501] /mnt/data/atr/src/huzaifa-vllm-profiling/.vllm/lib/python3.12/site-packages/vllm/model_executor/layers/utils.py
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:55 [backends.py:501] /mnt/data/atr/src/huzaifa-vllm-profiling/.vllm/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:55 [backends.py:501] /mnt/data/atr/src/huzaifa-vllm-profiling/.vllm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:55 [backends.py:501] /mnt/data/atr/src/huzaifa-vllm-profiling/.vllm/lib/python3.12/site-packages/vllm/platforms/interface.py
[1;36m(EngineCore_0 pid=150328)[0;0m INFO 10-06 14:56:56 [backends.py:548] Using cache directory: /home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_0 pid=150328)[0;0m INFO 10-06 14:56:56 [backends.py:559] Dynamo bytecode transform time: 5.35 s
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:56 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:56 [vllm_inductor_pass.py:40] FixFunctionalizationPass completed in 0.1 ms
[1;36m(EngineCore_0 pid=150328)[0;0m INFO 10-06 14:56:57 [backends.py:194] Cache the graph for dynamic shape for later use
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:57 [backends.py:200] Store the 0-th graph for dynamic shape from inductor via handle ('fx34a3knwub3tu34vozduj6mii373jejp3cptalksu3lyqbmhnb7', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/5u/c5u6koexqz5p4l2qopcmbvtsdunkzhxxhjxxcf4eatjxu6nhumtm.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:58 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:58 [vllm_inductor_pass.py:40] FixFunctionalizationPass completed in 0.1 ms
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:59 [backends.py:200] Store the 1-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:56:59 [backends.py:200] Store the 2-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:00 [backends.py:200] Store the 3-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:00 [backends.py:200] Store the 4-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:01 [backends.py:200] Store the 5-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:01 [backends.py:200] Store the 6-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:01 [backends.py:200] Store the 7-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:02 [backends.py:200] Store the 8-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:02 [backends.py:200] Store the 9-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:02 [backends.py:200] Store the 10-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:03 [backends.py:200] Store the 11-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:03 [backends.py:200] Store the 12-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:04 [backends.py:200] Store the 13-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:04 [backends.py:200] Store the 14-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
DEBUG 10-06 14:57:04 [utils.py:750] Waiting for 1 local, 0 remote core engine proc(s) to start.
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:04 [backends.py:200] Store the 15-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:05 [backends.py:200] Store the 16-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:05 [backends.py:200] Store the 17-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:05 [backends.py:200] Store the 18-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:06 [backends.py:200] Store the 19-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:07 [backends.py:200] Store the 20-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:07 [backends.py:200] Store the 21-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:07 [backends.py:200] Store the 22-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:08 [backends.py:200] Store the 23-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:08 [backends.py:200] Store the 24-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:08 [backends.py:200] Store the 25-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:09 [backends.py:200] Store the 26-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:09 [backends.py:200] Store the 27-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:10 [backends.py:200] Store the 28-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:10 [backends.py:200] Store the 29-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:10 [backends.py:200] Store the 30-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:11 [backends.py:200] Store the 31-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:11 [backends.py:200] Store the 32-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:11 [backends.py:200] Store the 33-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:12 [backends.py:200] Store the 34-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:12 [backends.py:200] Store the 35-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:13 [backends.py:200] Store the 36-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:13 [backends.py:200] Store the 37-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:14 [backends.py:200] Store the 38-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:14 [backends.py:200] Store the 39-th graph for dynamic shape from inductor via handle ('fv4illbxmz343k2ts7wumc577hnpzwpqrqetf7ufcutvfzsqypuy', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/ld/cldvft7bj7sorsc6rythyv3ka44mdrmawb33rl3s4c64yi6o3tmp.py')
DEBUG 10-06 14:57:14 [utils.py:750] Waiting for 1 local, 0 remote core engine proc(s) to start.
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:14 [fix_functionalization.py:104] De-functionalized 0 nodes, removed 0 nodes
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:14 [vllm_inductor_pass.py:40] FixFunctionalizationPass completed in 0.1 ms
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:14 [backends.py:200] Store the 40-th graph for dynamic shape from inductor via handle ('f2ddei4w2mumhig4lnczsoxw4z2d2k2mqan7lbw4btbrexngyvl5', '/home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/inductor_cache/5s/c5s4633m4d2bd5dq3dttjpsfp4q4zanuz3wnbpw7xdirjbza6gj2.py')
[1;36m(EngineCore_0 pid=150328)[0;0m INFO 10-06 14:57:14 [backends.py:215] Compiling a graph for dynamic shape takes 18.40 s
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:14 [backends.py:602] Computation graph saved to /home/atr/.cache/vllm/torch_compile_cache/01198297a2/rank_0_0/backbone/computation_graph.py
DEBUG 10-06 14:57:24 [utils.py:750] Waiting for 1 local, 0 remote core engine proc(s) to start.
[1;36m(EngineCore_0 pid=150328)[0;0m INFO 10-06 14:57:25 [monitor.py:34] torch.compile takes 23.75 s in total
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:26 [gpu_worker.py:262] Initial free memory: 43.90 GiB; Requested memory: 0.90 (util), 39.95 GiB
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:26 [gpu_worker.py:269] Free memory after profiling: 17.43 GiB (total), 13.47 GiB (within requested)
[1;36m(EngineCore_0 pid=150328)[0;0m DEBUG 10-06 14:57:26 [gpu_worker.py:275] Memory profiling takes 35.98 seconds. Total non KV cache memory: 27.16GiB; torch peak memory increase: 0.72GiB; non-torch forward increase memory: 0.02GiB; weights memory: 26.43GiB.
[1;36m(EngineCore_0 pid=150328)[0;0m INFO 10-06 14:57:26 [gpu_worker.py:276] Available KV cache memory: 12.79 GiB
[1;36m(EngineCore_0 pid=150328)[0;0m ERROR 10-06 14:57:27 [core.py:700] EngineCore failed to start.
[1;36m(EngineCore_0 pid=150328)[0;0m ERROR 10-06 14:57:27 [core.py:700] Traceback (most recent call last):
[1;36m(EngineCore_0 pid=150328)[0;0m ERROR 10-06 14:57:27 [core.py:700]   File "/mnt/data/atr/src/huzaifa-vllm-profiling/.vllm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 691, in run_engine_core
[1;36m(EngineCore_0 pid=150328)[0;0m ERROR 10-06 14:57:27 [core.py:700]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_0 pid=150328)[0;0m ERROR 10-06 14:57:27 [core.py:700]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=150328)[0;0m ERROR 10-06 14:57:27 [core.py:700]   File "/mnt/data/atr/src/huzaifa-vllm-profiling/.vllm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 492, in __init__
[1;36m(EngineCore_0 pid=150328)[0;0m ERROR 10-06 14:57:27 [core.py:700]     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_0 pid=150328)[0;0m ERROR 10-06 14:57:27 [core.py:700]   File "/mnt/data/atr/src/huzaifa-vllm-profiling/.vllm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 89, in __init__
[1;36m(EngineCore_0 pid=150328)[0;0m ERROR 10-06 14:57:27 [core.py:700]     self._initialize_kv_caches(vllm_config)
[1;36m(EngineCore_0 pid=150328)[0;0m ERROR 10-06 14:57:27 [core.py:700]   File "/mnt/data/atr/src/huzaifa-vllm-profiling/.vllm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 189, in _initialize_kv_caches
[1;36m(EngineCore_0 pid=150328)[0;0m ERROR 10-06 14:57:27 [core.py:700]     get_kv_cache_config(vllm_config, kv_cache_spec_one_worker,
[1;36m(EngineCore_0 pid=150328)[0;0m ERROR 10-06 14:57:27 [core.py:700]   File "/mnt/data/atr/src/huzaifa-vllm-profiling/.vllm/lib/python3.12/site-packages/vllm/v1/core/kv_cache_utils.py", line 1095, in get_kv_cache_config
[1;36m(EngineCore_0 pid=150328)[0;0m ERROR 10-06 14:57:27 [core.py:700]     check_enough_kv_cache_memory(vllm_config, kv_cache_spec, available_memory)
[1;36m(EngineCore_0 pid=150328)[0;0m ERROR 10-06 14:57:27 [core.py:700]   File "/mnt/data/atr/src/huzaifa-vllm-profiling/.vllm/lib/python3.12/site-packages/vllm/v1/core/kv_cache_utils.py", line 699, in check_enough_kv_cache_memory
[1;36m(EngineCore_0 pid=150328)[0;0m ERROR 10-06 14:57:27 [core.py:700]     raise ValueError(
[1;36m(EngineCore_0 pid=150328)[0;0m ERROR 10-06 14:57:27 [core.py:700] ValueError: To serve at least one request with the models's max seq len (32768), (25.00 GiB KV cache is needed, which is larger than the available KV cache memory (12.79 GiB). Based on the available memory, the estimated maximum model length is 16752. Try increasing `gpu_memory_utilization` or decreasing `max_model_len` when initializing the engine.
