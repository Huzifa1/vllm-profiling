{
    "labels": [
        "output_model_llama2-13b-hf_default.txt",
        "output_model_llama2-13b-hf_tmpfs.txt",
        "output_model_llama3-3b_default.txt",
        "output_model_llama3-3b_tmpfs.txt",
        "output_model_qwen-7b_default.txt",
        "output_model_qwen-7b_tmpfs.txt"
    ],
    "data": {
        "load_weights": [
            3.558,
            3.554,
            0.8699999999999999,
            0.874,
            2.09,
            2.1100000000000003
        ],
        "model_init": [
            0.126,
            0.124,
            0.13,
            0.13,
            0.118,
            0.12
        ],
        "model_loading": [
            3.6839999999999997,
            3.678,
            0.9999999999999999,
            1.004,
            2.2079999999999997,
            2.2300000000000004
        ],
        "dynamo_transform_time": [
            6.536,
            6.524000000000001,
            4.572,
            4.582,
            5.252000000000001,
            5.232
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_cached": [
            5.532000000000001,
            5.448,
            3.9298,
            3.939,
            4.300800000000001,
            4.264
        ],
        "torch.compile": [
            6.536,
            6.524000000000001,
            4.572,
            4.582,
            5.252000000000001,
            5.232
        ],
        "kv_cache_profiling": [
            14.47,
            14.376000000000001,
            10.068000000000001,
            10.084,
            11.280000000000001,
            11.232
        ],
        "graph_capturing": [
            1.4540000000000002,
            1.458,
            1.012,
            1.014,
            1.132,
            1.138
        ],
        "init_engine": [
            15.924000000000001,
            15.834000000000001,
            11.080000000000002,
            11.097999999999999,
            12.412,
            12.37
        ],
        "tokenizer_init": [
            0.084,
            0.08,
            0.28400000000000003,
            0.28400000000000003,
            0.248,
            0.248
        ],
        "total_time": [
            19.692,
            19.592,
            12.364000000000003,
            12.386,
            14.868,
            14.847999999999999
        ],
        "actual_total_time": [
            26.955890800000002,
            26.853740600000002,
            20.428727400000003,
            19.8722542,
            22.2971724,
            22.2893708
        ]
    }
}