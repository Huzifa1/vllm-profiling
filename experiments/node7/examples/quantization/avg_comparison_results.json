{
    "labels": [
        "output_model_llama2-7b-hf-awq_quantization_awq.txt",
        "output_model_llama2-7b-hf-gptq_quantization_gptq.txt",
        "output_model_llama2-7b-hf_quantization_bitsandbytes.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_mistral-7b-awq_quantization_awq_dtype_float16.txt",
        "output_model_mistral-7b-gptq_quantization_gptq_dtype_float16.txt",
        "output_model_mistral-7b_quantization_bitsandbytes.txt",
        "output_model_mistral-7b.txt"
    ],
    "data": {
        "detect_platform": [
            0.2,
            0.0,
            0.0,
            0.0,
            0.0,
            0.4,
            0.0,
            0.0
        ],
        "llm_imports": [
            1.2,
            1.8,
            1.6,
            1.6,
            1.2,
            1.6,
            1.4,
            1.2
        ],
        "get_model_info": [
            5.4,
            5.4,
            4.4,
            4.4,
            5.8,
            5.4,
            4.6,
            4.8
        ],
        "worker_init": [
            0.6,
            0.4,
            1.0,
            1.6,
            0.8,
            0.8,
            1.0,
            1.4
        ],
        "framework_bootstrap": [
            7.4,
            7.6000000000000005,
            7.0,
            7.6,
            7.8,
            8.200000000000001,
            7.0,
            7.4
        ],
        "load_weights": [
            0.5820000000000001,
            0.58,
            1.9683125999999997,
            1.7740000000000002,
            0.6219999999999999,
            0.6379999999999999,
            2.0857979999999996,
            1.8959999999999997
        ],
        "model_init": [
            0.12,
            0.178,
            0.56,
            0.11599999999999999,
            0.12,
            0.18,
            0.56,
            0.11599999999999999
        ],
        "model_loading": [
            0.7020000000000001,
            0.758,
            2.5283125999999996,
            1.8900000000000001,
            0.7419999999999999,
            0.8179999999999998,
            2.6457979999999997,
            2.0119999999999996
        ],
        "dynamo_transform_time": [
            5.892,
            5.382,
            5.843999999999999,
            5.204,
            5.88,
            5.42,
            5.6899999999999995,
            5.13
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_cached": [
            4.219799999999999,
            3.8176,
            4.579199999999999,
            4.2942,
            4.4352,
            4.105200000000001,
            4.293200000000001,
            4.4946
        ],
        "torch.compile": [
            5.892,
            5.382,
            5.843999999999999,
            5.204,
            5.88,
            5.42,
            5.6899999999999995,
            5.13
        ],
        "kv_cache_profiling": [
            1.6762000000000001,
            1.7424,
            1.7788000000000004,
            1.6957999999999995,
            1.6687999999999998,
            1.7528,
            1.6907999999999999,
            1.6614000000000004
        ],
        "graph_capturing": [
            2.074,
            1.27,
            3.396,
            1.098,
            2.186,
            1.282,
            2.748,
            1.166
        ],
        "init_engine": [
            13.861999999999998,
            12.212,
            15.597999999999999,
            12.291999999999998,
            14.169999999999998,
            12.56,
            14.421999999999999,
            12.452000000000002
        ],
        "tokenizer_init": [
            0.08,
            0.08,
            0.08,
            0.08,
            0.064,
            0.064,
            0.068,
            0.07
        ],
        "total_time": [
            22.043999999999997,
            20.65,
            25.206312599999997,
            21.861999999999995,
            22.775999999999996,
            21.642000000000003,
            24.135797999999998,
            21.934
        ],
        "actual_total_time": [
            23.0972032,
            25.9265924,
            26.483999999999998,
            22.742802199999996,
            23.491184199999996,
            26.034528400000003,
            25.703999999999997,
            22.7402144
        ]
    }
}