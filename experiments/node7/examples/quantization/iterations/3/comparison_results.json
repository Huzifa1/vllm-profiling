{
    "labels": [
        "output_model_llama2-7b-hf-awq_quantization_awq.txt",
        "output_model_llama2-7b-hf-gptq_quantization_gptq.txt",
        "output_model_llama2-7b-hf_quantization_bitsandbytes.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_mistral-7b-awq_quantization_awq_dtype_float16.txt",
        "output_model_mistral-7b-gptq_quantization_gptq_dtype_float16.txt",
        "output_model_mistral-7b_quantization_bitsandbytes.txt",
        "output_model_mistral-7b.txt"
    ],
    "data": {
        "load_weights": [
            0.59,
            0.58,
            1.9661119999999999,
            1.76,
            0.59,
            0.61,
            2.095991,
            1.9
        ],
        "model_init": [
            0.12,
            0.18,
            0.56,
            0.11,
            0.12,
            0.18,
            0.56,
            0.11
        ],
        "model_loading": [
            0.71764,
            0.768357,
            2.526112,
            1.876778,
            0.721405,
            0.888894,
            2.655991,
            2.016319
        ],
        "dynamo_transform_time": [
            5.86,
            5.47,
            5.78,
            5.28,
            5.83,
            5.43,
            5.68,
            5.12
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_cached": [
            4.177,
            3.754,
            4.505,
            4.284,
            4.42,
            4.0,
            4.25,
            4.502
        ],
        "torch.compile": [
            5.86,
            5.47,
            5.78,
            5.28,
            5.83,
            5.43,
            5.68,
            5.12
        ],
        "kv_cache_profiling": [
            11.7,
            10.96,
            12.06,
            11.27,
            11.92,
            11.17,
            11.62,
            11.28
        ],
        "graph_capturing": [
            2.07,
            1.27,
            3.39,
            1.1,
            2.18,
            1.28,
            2.74,
            1.16
        ],
        "init_engine": [
            14.27,
            12.7,
            15.97,
            12.82,
            14.6,
            12.92,
            14.86,
            12.9
        ],
        "tokenizer_init": [
            0.08,
            0.08,
            0.08,
            0.08,
            0.06,
            0.06,
            0.07,
            0.07
        ],
        "total_time": [
            15.067639999999999,
            13.548357,
            18.576112,
            14.776778,
            15.381405,
            13.868894000000001,
            17.585991,
            14.986319000000002
        ],
        "actual_total_time": [
            22.13,
            25.0,
            25.64,
            21.82,
            22.42,
            25.3,
            24.65,
            22.0
        ]
    }
}