{
    "labels": [
        "output_model_llama2-7b-hf-awq_quantization_awq.txt",
        "output_model_llama2-7b-hf-gptq_quantization_gptq.txt",
        "output_model_llama2-7b-hf_quantization_bitsandbytes.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_mistral-7b-awq_quantization_awq_dtype_float16.txt",
        "output_model_mistral-7b-gptq_quantization_gptq_dtype_float16.txt",
        "output_model_mistral-7b_quantization_bitsandbytes.txt",
        "output_model_mistral-7b.txt"
    ],
    "data": {
        "load_weights": [
            0.58,
            0.58,
            1.9650159999999999,
            1.77,
            0.59,
            0.61,
            2.0836639999999997,
            1.9
        ],
        "model_init": [
            0.12,
            0.18,
            0.56,
            0.12,
            0.12,
            0.18,
            0.56,
            0.12
        ],
        "model_loading": [
            0.705805,
            0.766453,
            2.525016,
            1.893148,
            0.717678,
            0.885192,
            2.643664,
            2.015796
        ],
        "dynamo_transform_time": [
            5.84,
            5.33,
            6.02,
            5.39,
            5.91,
            5.39,
            5.62,
            5.11
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_cached": [
            4.18,
            3.912,
            4.721,
            4.468,
            4.436,
            4.208,
            4.274,
            4.481
        ],
        "torch.compile": [
            5.84,
            5.33,
            6.02,
            5.39,
            5.91,
            5.39,
            5.62,
            5.11
        ],
        "kv_cache_profiling": [
            11.7,
            10.98,
            12.52,
            11.57,
            12.03,
            11.37,
            11.59,
            11.26
        ],
        "graph_capturing": [
            2.08,
            1.27,
            3.39,
            1.1,
            2.19,
            1.29,
            2.75,
            1.18
        ],
        "init_engine": [
            14.27,
            12.71,
            16.42,
            13.13,
            14.72,
            13.13,
            14.84,
            12.91
        ],
        "tokenizer_init": [
            0.08,
            0.08,
            0.08,
            0.08,
            0.07,
            0.07,
            0.07,
            0.07
        ],
        "total_time": [
            15.055805,
            13.556453000000001,
            19.025016,
            15.103148000000001,
            15.507678,
            14.085192000000001,
            17.553664,
            14.995796
        ],
        "actual_total_time": [
            22.14,
            25.03,
            26.13,
            22.14,
            22.54,
            25.55,
            24.63,
            22.05
        ]
    }
}