{
    "labels": [
        "output_model_falcon-7b.txt",
        "output_model_llama2-13b-hf.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_llama3-3b.txt",
        "output_model_qwen-0.5b.txt",
        "output_model_qwen-14b_max_model_len_16752.txt",
        "output_model_qwen-1.8b.txt",
        "output_model_qwen-4b.txt",
        "output_model_qwen-7b.txt",
        "output_model_yi-6b.txt",
        "output_model_yi-9b.txt"
    ],
    "data": {
        "detect_platfrom": [
            0.047,
            0.046,
            0.046,
            0.047,
            0.047,
            0.046,
            0.046,
            0.047,
            0.046,
            0.046,
            0.047
        ],
        "llm_imports": [
            1.31,
            1.315,
            1.37,
            1.315,
            1.322,
            1.314,
            1.317,
            1.308,
            1.315,
            1.32,
            1.315
        ],
        "get_model_info": [
            4.701,
            4.679,
            4.678,
            4.681,
            4.672,
            4.686,
            4.684,
            4.682,
            4.691,
            4.68,
            4.682
        ],
        "worker_init": [
            1.532,
            1.526,
            1.529,
            1.554,
            1.572,
            1.556,
            1.553,
            1.545,
            1.555,
            1.558,
            1.55
        ],
        "framework_bootstrap": [
            7.59,
            7.566,
            7.623,
            7.597,
            7.6129999999999995,
            7.602,
            7.6000000000000005,
            7.582000000000001,
            7.606999999999999,
            7.603999999999999,
            7.594
        ],
        "load_weights": [
            1.87,
            3.46,
            1.76,
            0.85,
            0.14,
            3.72,
            0.5,
            1.05,
            2.06,
            1.66,
            2.36
        ],
        "model_init": [
            0.11,
            0.12,
            0.11,
            0.13,
            0.09,
            0.12,
            0.1,
            0.12,
            0.11,
            0.11,
            0.13
        ],
        "model_loading": [
            1.983988,
            3.584317,
            1.871518,
            0.981624,
            0.240507,
            3.851767,
            0.601261,
            1.174986,
            2.175685,
            1.772644,
            2.49525
        ],
        "dynamo_transform_time": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
        ],
        "graph_compile_general_shape": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
        ],
        "graph_compile_cached": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
        ],
        "torch.compile": [
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
        ],
        "kv_cache_profiling": [
            0.71,
            0.89,
            0.75,
            0.65,
            0.61,
            0.88,
            0.62,
            0.67,
            0.75,
            0.72,
            0.78
        ],
        "graph_capturing": [
            2.0,
            3.7,
            2.13,
            1.21,
            0.98,
            3.68,
            0.93,
            1.43,
            2.14,
            1.91,
            2.73
        ],
        "init_engine": [
            3.14,
            5.03,
            3.31,
            2.28,
            2.01,
            5.02,
            1.95,
            2.51,
            3.31,
            3.06,
            3.94
        ],
        "tokenizer_init": [
            0.12,
            0.08,
            0.08,
            0.28,
            0.24,
            0.25,
            0.24,
            0.24,
            0.25,
            0.15,
            0.15
        ],
        "total_time": [
            12.833988,
            16.260316999999997,
            12.884518,
            11.138624,
            10.103506999999999,
            16.723767000000002,
            10.391261,
            11.506986000000001,
            13.342685,
            12.586644,
            14.17925
        ],
        "actual_total_time": [
            13.989,
            17.089,
            13.715,
            12.18,
            11.11,
            17.71,
            11.379,
            12.496,
            14.344,
            13.504,
            15.072
        ]
    }
}