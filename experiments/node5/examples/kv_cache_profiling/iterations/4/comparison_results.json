{
    "labels": [
        "output_model_falcon-7b.txt",
        "output_model_llama2-13b-hf.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_llama3-3b.txt",
        "output_model_qwen-0.5b.txt",
        "output_model_qwen-14b_max_model_len_16752.txt",
        "output_model_qwen-1.8b.txt",
        "output_model_qwen-4b.txt",
        "output_model_qwen-7b.txt",
        "output_model_yi-6b.txt",
        "output_model_yi-9b.txt"
    ],
    "data": {
        "detect_platform": [
            0.046,
            0.047,
            0.046,
            0.047,
            0.047,
            0.046,
            0.047,
            0.047,
            0.046,
            0.046,
            0.046
        ],
        "llm_imports": [
            1.319,
            1.322,
            1.314,
            1.309,
            1.318,
            1.318,
            1.314,
            1.317,
            1.314,
            1.321,
            1.32
        ],
        "get_model_info": [
            4.689,
            4.696,
            4.689,
            4.68,
            4.685,
            4.695,
            4.69,
            4.697,
            4.689,
            4.693,
            4.689
        ],
        "worker_init": [
            1.536,
            1.541,
            1.527,
            1.548,
            1.552,
            1.559,
            1.578,
            1.568,
            1.57,
            1.542,
            1.552
        ],
        "framework_bootstrap": [
            7.59,
            7.606,
            7.5760000000000005,
            7.584,
            7.602,
            7.618,
            7.6290000000000004,
            7.629,
            7.619000000000001,
            7.601999999999999,
            7.606999999999999
        ],
        "load_weights": [
            1.88,
            3.47,
            1.77,
            0.85,
            0.14,
            3.71,
            0.5,
            1.05,
            2.05,
            1.64,
            2.37
        ],
        "model_init": [
            0.11,
            0.12,
            0.11,
            0.13,
            0.09,
            0.12,
            0.1,
            0.12,
            0.11,
            0.11,
            0.13
        ],
        "model_loading": [
            1.991034,
            3.598172,
            1.889635,
            0.977173,
            0.238112,
            3.838659,
            0.601453,
            1.175185,
            2.168466,
            1.756515,
            2.50213
        ],
        "dynamo_transform_time": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_cached": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "torch.compile": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "kv_cache_profiling": [
            0.72,
            0.89,
            0.75,
            0.65,
            0.61,
            0.87,
            0.64,
            0.68,
            0.74,
            0.72,
            0.78
        ],
        "graph_capturing": [
            2.01,
            3.7,
            2.13,
            1.2,
            0.96,
            3.68,
            1.0,
            1.43,
            2.14,
            1.91,
            2.73
        ],
        "init_engine": [
            3.15,
            5.05,
            3.31,
            2.25,
            1.97,
            5.0,
            2.05,
            2.52,
            3.3,
            3.05,
            3.95
        ],
        "tokenizer_init": [
            0.12,
            0.08,
            0.08,
            0.29,
            0.25,
            0.25,
            0.25,
            0.25,
            0.25,
            0.16,
            0.16
        ],
        "total_time": [
            12.851033999999999,
            16.334172,
            12.855635000000001,
            11.101173,
            10.060112,
            16.706659000000002,
            10.530453000000001,
            11.574185,
            13.337466,
            12.568514999999998,
            14.21913
        ],
        "actual_total_time": [
            14.019,
            17.171,
            13.69,
            12.149,
            11.076,
            17.692,
            11.541,
            12.572,
            14.324,
            13.475,
            15.107
        ]
    }
}