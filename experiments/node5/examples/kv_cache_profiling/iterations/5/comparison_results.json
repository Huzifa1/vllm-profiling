{
    "labels": [
        "output_model_falcon-7b.txt",
        "output_model_llama2-13b-hf.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_llama3-3b.txt",
        "output_model_qwen-0.5b.txt",
        "output_model_qwen-14b_max_model_len_16752.txt",
        "output_model_qwen-1.8b.txt",
        "output_model_qwen-4b.txt",
        "output_model_qwen-7b.txt",
        "output_model_yi-6b.txt",
        "output_model_yi-9b.txt"
    ],
    "data": {
        "detect_platfrom": [
            0.047,
            0.047,
            0.047,
            0.047,
            0.047,
            0.046,
            0.046,
            0.047,
            0.046,
            0.047,
            0.046
        ],
        "llm_imports": [
            1.315,
            1.317,
            1.322,
            1.314,
            1.312,
            1.31,
            1.327,
            1.357,
            1.309,
            1.316,
            1.322
        ],
        "get_model_info": [
            4.701,
            4.675,
            4.698,
            4.679,
            4.704,
            4.697,
            4.688,
            4.682,
            4.696,
            4.684,
            4.69
        ],
        "worker_init": [
            1.516,
            1.523,
            1.548,
            1.55,
            1.549,
            1.547,
            1.596,
            1.552,
            1.56,
            1.53,
            1.559
        ],
        "framework_bootstrap": [
            7.579,
            7.561999999999999,
            7.615,
            7.59,
            7.612,
            7.6,
            7.657,
            7.638,
            7.611000000000001,
            7.577000000000001,
            7.617000000000001
        ],
        "load_weights": [
            1.88,
            3.46,
            1.76,
            0.85,
            0.14,
            3.71,
            0.49,
            1.05,
            2.07,
            1.64,
            2.36
        ],
        "model_init": [
            0.11,
            0.12,
            0.11,
            0.13,
            0.09,
            0.12,
            0.1,
            0.12,
            0.11,
            0.11,
            0.13
        ],
        "model_loading": [
            1.997766,
            3.585015,
            1.879603,
            0.984916,
            0.237987,
            3.835607,
            0.598104,
            1.170032,
            2.185797,
            1.757408,
            2.496901
        ],
        "dynamo_transform_time": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_cached": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "torch.compile": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "kv_cache_profiling": [
            0.71,
            0.88,
            0.75,
            0.65,
            0.6,
            0.88,
            0.63,
            0.68,
            0.75,
            0.73,
            0.79
        ],
        "graph_capturing": [
            2.01,
            3.69,
            2.13,
            1.21,
            0.97,
            3.68,
            0.94,
            1.43,
            2.14,
            1.91,
            2.73
        ],
        "init_engine": [
            3.13,
            5.02,
            3.29,
            2.27,
            1.97,
            5.01,
            1.97,
            2.52,
            3.32,
            3.06,
            3.97
        ],
        "tokenizer_init": [
            0.12,
            0.08,
            0.08,
            0.29,
            0.25,
            0.25,
            0.25,
            0.25,
            0.25,
            0.16,
            0.15
        ],
        "total_time": [
            12.826765999999997,
            16.247014999999998,
            12.864603,
            11.134915999999999,
            10.069987000000001,
            16.695607,
            10.475104,
            11.578032,
            13.366797000000002,
            12.554408000000002,
            14.233901000000001
        ],
        "actual_total_time": [
            13.984,
            17.068,
            13.692,
            12.169,
            11.061,
            17.688,
            11.465,
            12.562,
            14.368,
            13.455,
            15.13
        ]
    }
}