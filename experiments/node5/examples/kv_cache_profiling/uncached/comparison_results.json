{
    "labels": [
        "output_model_falcon-7b.txt",
        "output_model_llama2-13b-hf.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_llama3-3b.txt",
        "output_model_qwen-0.5b.txt",
        "output_model_qwen-14b_max_model_len_16752.txt",
        "output_model_qwen-1.8b.txt",
        "output_model_qwen-4b.txt",
        "output_model_qwen-7b.txt",
        "output_model_yi-6b.txt",
        "output_model_yi-9b.txt"
    ],
    "data": {
        "detect_platform": [
            0.047,
            0.046,
            0.046,
            0.047,
            0.046,
            0.046,
            0.047,
            0.046,
            0.046,
            0.046,
            0.046
        ],
        "llm_imports": [
            1.328,
            1.322,
            1.328,
            1.311,
            1.316,
            1.319,
            1.321,
            1.346,
            1.305,
            1.312,
            1.311
        ],
        "get_model_info": [
            4.706,
            4.722,
            4.696,
            4.7,
            4.712,
            4.691,
            4.691,
            4.808,
            4.704,
            4.683,
            4.715
        ],
        "worker_init": [
            1.529,
            1.533,
            1.539,
            1.557,
            1.589,
            1.551,
            1.647,
            1.582,
            1.552,
            1.544,
            1.544
        ],
        "framework_bootstrap": [
            7.61,
            7.623000000000001,
            7.609,
            7.615,
            7.663,
            7.607,
            7.7059999999999995,
            7.782,
            7.606999999999999,
            7.585000000000001,
            7.616
        ],
        "load_weights": [
            1.88,
            3.46,
            1.76,
            0.85,
            0.14,
            3.73,
            0.5,
            1.06,
            2.06,
            1.64,
            2.37
        ],
        "model_init": [
            0.11,
            0.12,
            0.11,
            0.13,
            0.1,
            0.12,
            0.11,
            0.12,
            0.11,
            0.11,
            0.13
        ],
        "model_loading": [
            1.998554,
            3.589802,
            1.875681,
            0.9858,
            0.239644,
            3.851863,
            0.612999,
            1.185173,
            2.176111,
            1.752768,
            2.501475
        ],
        "dynamo_transform_time": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_cached": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "torch.compile": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "kv_cache_profiling": [
            0.74,
            0.91,
            0.76,
            0.65,
            0.61,
            0.87,
            0.69,
            0.73,
            0.75,
            0.71,
            0.79
        ],
        "graph_capturing": [
            2.01,
            3.7,
            2.13,
            1.21,
            0.99,
            3.68,
            0.96,
            1.44,
            2.14,
            1.9,
            2.73
        ],
        "init_engine": [
            3.17,
            5.06,
            3.31,
            2.27,
            2.01,
            5.0,
            2.07,
            2.58,
            3.3,
            3.03,
            3.96
        ],
        "tokenizer_init": [
            0.12,
            0.08,
            0.08,
            0.29,
            0.25,
            0.25,
            0.25,
            0.26,
            0.24,
            0.16,
            0.16
        ],
        "total_time": [
            12.898553999999999,
            16.352802,
            12.874681,
            11.160799999999998,
            10.162644,
            16.708863,
            10.638999,
            11.807173,
            13.323110999999999,
            12.527768,
            14.237475
        ],
        "actual_total_time": [
            14.069,
            17.184,
            13.711,
            12.2,
            11.169,
            17.702,
            11.651,
            12.806,
            14.315,
            13.422,
            15.144
        ]
    }
}