{
    "labels": [
        "output_model_falcon-7b.txt",
        "output_model_llama2-13b-hf.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_llama3-3b.txt",
        "output_model_qwen-0.5b.txt",
        "output_model_qwen-14b.txt",
        "output_model_qwen-1.8b.txt",
        "output_model_qwen-4b.txt",
        "output_model_qwen-7b.txt",
        "output_model_yi-6b.txt",
        "output_model_yi-9b.txt"
    ],
    "data": {
        "detect_platfrom": [
            0.046,
            0.046,
            0.046,
            0.046,
            0.046,
            0.047,
            0.047,
            0.046,
            0.046,
            0.046,
            0.046
        ],
        "llm_imports": [
            1.316,
            1.314,
            1.31,
            1.315,
            1.325,
            1.317,
            1.318,
            1.297,
            1.304,
            1.305,
            1.319
        ],
        "get_model_info": [
            4.686,
            4.67,
            4.683,
            4.671,
            4.71,
            4.714,
            4.683,
            4.691,
            4.683,
            4.676,
            4.675
        ],
        "worker_init": [
            1.523,
            1.542,
            1.528,
            1.547,
            1.549,
            1.567,
            1.574,
            1.571,
            1.567,
            1.555,
            1.562
        ],
        "framework_bootstrap": [
            7.571,
            7.572,
            7.567,
            7.579,
            7.629999999999999,
            7.6450000000000005,
            7.622,
            7.6049999999999995,
            7.6,
            7.582,
            7.602
        ],
        "load_weights": [
            1.87,
            3.46,
            1.77,
            0.85,
            0.14,
            3.71,
            0.49,
            1.05,
            2.06,
            1.66,
            2.37
        ],
        "model_init": [
            0.11,
            0.12,
            0.11,
            0.13,
            0.09,
            0.12,
            0.1,
            0.12,
            0.11,
            0.11,
            0.13
        ],
        "model_loading": [
            1.984889,
            3.589676,
            1.888102,
            0.977804,
            0.239085,
            3.838493,
            0.598404,
            1.173285,
            2.176869,
            1.776455,
            2.504188
        ],
        "dynamo_transform_time": [
            4.53,
            6.47,
            5.2,
            4.59,
            4.3,
            6.61,
            4.07,
            6.94,
            5.24,
            5.38,
            7.69
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_cached": [
            3.933,
            5.276,
            4.276,
            3.912,
            3.479,
            5.293,
            3.426,
            5.563,
            4.233,
            4.684,
            6.728
        ],
        "torch.compile": [
            4.53,
            6.47,
            5.2,
            4.59,
            4.3,
            6.61,
            4.07,
            6.94,
            5.24,
            5.38,
            7.69
        ],
        "kv_cache_profiling": [
            10.16,
            13.56,
            11.27,
            10.09,
            9.02,
            13.76,
            8.75,
            14.2,
            11.27,
            11.83,
            16.35
        ],
        "graph_capturing": [
            1.49,
            2.34,
            1.48,
            0.99,
            0.65,
            2.35,
            0.73,
            1.2,
            1.5,
            1.39,
            1.97
        ],
        "init_engine": [
            12.12,
            16.42,
            13.23,
            11.54,
            10.11,
            16.62,
            9.92,
            15.88,
            13.25,
            13.69,
            18.83
        ],
        "tokenizer_init": [
            0.12,
            0.08,
            0.08,
            0.29,
            0.25,
            0.25,
            0.25,
            0.25,
            0.25,
            0.15,
            0.16
        ],
        "total_time": [
            21.795889,
            27.661676,
            22.765102,
            20.386803999999998,
            18.229084999999998,
            28.353493,
            18.390404,
            24.908285,
            23.276868999999998,
            23.198454999999996,
            29.096187999999998
        ],
        "actual_total_time": [
            22.996,
            28.487,
            23.599,
            21.415,
            19.214,
            29.339,
            19.377,
            25.908,
            24.268,
            24.119,
            29.998
        ]
    }
}