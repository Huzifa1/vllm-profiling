{
    "labels": [
        "output_model_falcon-7b.txt",
        "output_model_llama2-13b-hf.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_llama3-3b.txt",
        "output_model_qwen-0.5b.txt",
        "output_model_qwen-14b_max_model_len_16752.txt",
        "output_model_qwen-1.8b.txt",
        "output_model_qwen-4b.txt",
        "output_model_qwen-7b.txt",
        "output_model_yi-6b.txt",
        "output_model_yi-9b.txt"
    ],
    "data": {
        "detect_platfrom": [
            0.046,
            0.046,
            0.046,
            0.046,
            0.046,
            0.046,
            0.046,
            0.046,
            0.046,
            0.046,
            0.046
        ],
        "llm_imports": [
            1.322,
            1.314,
            1.322,
            1.312,
            1.32,
            1.319,
            1.322,
            1.311,
            1.319,
            1.307,
            1.357
        ],
        "get_model_info": [
            4.687,
            4.691,
            4.722,
            4.671,
            4.688,
            4.699,
            4.71,
            4.7,
            4.713,
            4.705,
            4.695
        ],
        "worker_init": [
            1.543,
            1.535,
            1.551,
            1.577,
            1.561,
            1.554,
            1.593,
            1.56,
            1.574,
            1.56,
            1.544
        ],
        "framework_bootstrap": [
            7.598000000000001,
            7.586,
            7.641000000000001,
            7.606,
            7.615,
            7.618,
            7.671,
            7.617000000000001,
            7.652,
            7.618,
            7.642000000000001
        ],
        "load_weights": [
            1.89,
            3.45,
            1.77,
            0.84,
            0.14,
            3.72,
            0.5,
            1.05,
            2.06,
            1.66,
            2.38
        ],
        "model_init": [
            0.11,
            0.12,
            0.11,
            0.13,
            0.09,
            0.12,
            0.1,
            0.12,
            0.11,
            0.11,
            0.13
        ],
        "model_loading": [
            2.002482,
            3.573249,
            1.881995,
            0.973282,
            0.237753,
            3.849165,
            0.600207,
            1.171035,
            2.180699,
            1.771628,
            2.512354
        ],
        "dynamo_transform_time": [
            4.63,
            6.46,
            5.15,
            4.76,
            4.07,
            6.6,
            4.09,
            6.63,
            5.23,
            5.08,
            7.65
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_cached": [
            4.178,
            5.285,
            4.254,
            4.069,
            3.372,
            5.294,
            3.419,
            5.321,
            4.257,
            4.458,
            6.74
        ],
        "torch.compile": [
            4.63,
            6.46,
            5.15,
            4.76,
            4.07,
            6.6,
            4.09,
            6.63,
            5.23,
            5.08,
            7.65
        ],
        "kv_cache_profiling": [
            10.51,
            13.56,
            11.2,
            10.43,
            8.68,
            13.75,
            8.76,
            13.61,
            11.29,
            11.31,
            16.34
        ],
        "graph_capturing": [
            1.49,
            2.33,
            1.48,
            0.99,
            0.66,
            2.35,
            0.73,
            1.2,
            1.51,
            1.39,
            1.97
        ],
        "init_engine": [
            12.47,
            16.39,
            13.15,
            11.87,
            9.78,
            16.62,
            9.94,
            15.29,
            13.27,
            13.17,
            18.81
        ],
        "tokenizer_init": [
            0.12,
            0.08,
            0.08,
            0.28,
            0.25,
            0.25,
            0.25,
            0.25,
            0.25,
            0.15,
            0.15
        ],
        "total_time": [
            22.190482000000003,
            27.629249,
            22.752995,
            20.729281999999998,
            17.882753,
            28.337165000000002,
            18.461207,
            24.328035,
            23.352699,
            22.709628,
            29.114354
        ],
        "actual_total_time": [
            23.405,
            28.454,
            23.59,
            21.765,
            18.888,
            29.329,
            19.459,
            25.318,
            24.347,
            23.635,
            30.03
        ]
    }
}