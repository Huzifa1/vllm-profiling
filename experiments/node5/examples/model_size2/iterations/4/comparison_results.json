{
    "labels": [
        "output_model_falcon-7b.txt",
        "output_model_llama2-13b-hf.txt",
        "output_model_llama2-7b-hf.txt",
        "output_model_llama3-3b.txt",
        "output_model_qwen-0.5b.txt",
        "output_model_qwen-14b.txt",
        "output_model_qwen-1.8b.txt",
        "output_model_qwen-4b.txt",
        "output_model_qwen-7b.txt",
        "output_model_yi-6b.txt",
        "output_model_yi-9b.txt"
    ],
    "data": {
        "detect_platfrom": [
            0.047,
            0.046,
            0.046,
            0.047,
            0.046,
            0.047,
            0.046,
            0.046,
            0.047,
            0.046,
            0.046
        ],
        "llm_imports": [
            1.317,
            1.365,
            1.315,
            1.318,
            1.319,
            1.313,
            1.32,
            1.317,
            1.315,
            1.314,
            1.317
        ],
        "get_model_info": [
            4.703,
            4.709,
            4.684,
            4.695,
            4.68,
            4.679,
            4.691,
            4.691,
            4.688,
            4.72,
            4.696
        ],
        "worker_init": [
            1.547,
            1.528,
            1.544,
            1.584,
            1.553,
            1.551,
            1.576,
            1.564,
            1.554,
            1.581,
            1.55
        ],
        "framework_bootstrap": [
            7.614,
            7.648,
            7.589,
            7.644,
            7.598,
            7.59,
            7.633000000000001,
            7.618,
            7.604,
            7.661,
            7.608999999999999
        ],
        "load_weights": [
            1.9,
            3.47,
            1.76,
            0.85,
            0.14,
            3.72,
            0.49,
            1.05,
            2.06,
            1.64,
            2.37
        ],
        "model_init": [
            0.11,
            0.12,
            0.11,
            0.13,
            0.09,
            0.12,
            0.1,
            0.12,
            0.11,
            0.11,
            0.13
        ],
        "model_loading": [
            2.013017,
            3.589667,
            1.874532,
            0.981817,
            0.23847,
            3.847644,
            0.595579,
            1.177978,
            2.181535,
            1.760233,
            2.502652
        ],
        "dynamo_transform_time": [
            4.55,
            6.51,
            5.12,
            4.55,
            4.47,
            6.61,
            4.06,
            6.62,
            5.21,
            5.07,
            7.65
        ],
        "graph_compile_general_shape": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null
        ],
        "graph_compile_cached": [
            3.932,
            5.3,
            4.245,
            3.893,
            3.725,
            5.321,
            3.416,
            5.296,
            4.227,
            4.497,
            6.713
        ],
        "torch.compile": [
            4.55,
            6.51,
            5.12,
            4.55,
            4.47,
            6.61,
            4.06,
            6.62,
            5.21,
            5.07,
            7.65
        ],
        "kv_cache_profiling": [
            10.18,
            13.63,
            11.16,
            10.03,
            9.45,
            13.77,
            8.72,
            13.61,
            11.25,
            11.31,
            16.32
        ],
        "graph_capturing": [
            1.49,
            2.33,
            1.49,
            0.99,
            0.65,
            2.35,
            0.74,
            1.2,
            1.51,
            1.38,
            1.99
        ],
        "init_engine": [
            12.14,
            16.47,
            13.12,
            11.48,
            10.54,
            16.63,
            9.89,
            15.29,
            13.24,
            13.16,
            18.82
        ],
        "tokenizer_init": [
            0.12,
            0.08,
            0.08,
            0.28,
            0.25,
            0.25,
            0.25,
            0.25,
            0.25,
            0.16,
            0.15
        ],
        "total_time": [
            21.887017000000004,
            27.787667,
            22.663531999999996,
            20.385817000000003,
            18.626469999999998,
            28.317643999999998,
            18.368579000000004,
            24.335977999999997,
            23.275534999999998,
            22.741232999999998,
            29.081652
        ],
        "actual_total_time": [
            23.104,
            28.621,
            23.539,
            21.426,
            19.619,
            29.311,
            19.358,
            25.335,
            24.268,
            23.636,
            29.989
        ]
    }
}